<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>2</id>
  <title>Combined summary - Jamming Mitigation Dry Run</title>
  <updated>2023-08-04T02:18:44.126631+00:00</updated>
  <author>
    <name>Elias Rohrer 2023-08-03 08:54:06+00:00</name>
  </author>
  <author>
    <name>Carla KirkCohen 2023-08-01 18:44:57+00:00</name>
  </author>
  <link href="lightning-dev/Aug_2023/004036_Jamming-Mitigation-Dry-Run.xml" rel="alternate"/>
  <link href="lightning-dev/Aug_2023/004034_Jamming-Mitigation-Dry-Run.xml" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>2</id>
    <title>Combined summary - Jamming Mitigation Dry Run</title>
    <updated>2023-08-04T02:18:44.126679+00:00</updated>
    <link href="https://lists.linuxfoundation.org/pipermail/lightning-dev/2023-August/004036.html" rel="alternate"/>
    <summary>We are aware of the limitations posed by the lack of real-world datasets for conducting simulations and empirical experiments on Lightning. However, it is important to note that long-term collection of the proposed fields could potentially allow re-identification of anonymized channel counterparties based on heuristics correlating with public graph data. This becomes more significant when datasets from multiple collection points are combined, enabling further conclusions to be drawn about transferred amounts, channel liquidities, and even payment destinations' identities.Given the sensitive nature of the data, it is crucial to establish trust in the researchers who will have access to it. Therefore, it is recommended to clarify upfront whether there will be a time limit for data collection, where the data will be stored, and who will have access to it. Defining the collection period is mandatory to prevent node operators from collecting and storing HTLC data long-term, especially with such detailed information.To address the privacy concerns, a common data format is proposed, which will allow for analysis tooling to be built around it. Fields marked as [P] must be randomized if exported to researching teams. The suggested format is a CSV file with various fields including version, channel IDs, peer information, fee, outgoing liquidity and slots, timestamps, settlement status, and endorsement statuses. The last two values will be set to -1 until the experimental TLV for endorsements is propagated.The research plan also involves a "dry run" of HTLC endorsement and local reputation tracking. It aims to validate local reputation algorithms using real-world data, gather liquidity and slot utilization data, and establish a common data export format for analysis. The plan consists of phases such as collecting anonymized forwarding data, propagating an experimental endorsement TLV, and implementing local reputation algorithms.To propagate the experimental endorsement TLV, it will be included in the `update_add_htlc` message using a reserved range TLV. Forwarding nodes will handle the TLV by setting the same value for the outgoing `update_add_htlc` if the `endorsed` field is present in the incoming message. Otherwise, the value will be set to 0 for the outgoing `update_add_htlc`.The next step involves implementing local reputation algorithms and actively setting the value of the `endorsed` TLV for outgoing HTLCs. This signal will only be used for data collection purposes and will not affect the actual transaction. Experimenters have the freedom to use the full range of bits to express endorsement values, but any non-zero value will be interpreted as a positive endorsement signal.The research plan is a collaborative effort involving multiple teams working on different aspects. Eclair focuses on collecting local reputation data, CLN works on propagating the endorsement field and creating a plugin for local reputation scoring, LND handles data export and HTLC endorsement, and LDK requires additional plumbing work. Links to their respective GitHub repositories and pull requests are provided for further reference.In conclusion, the research plan aims to collect real-world data to validate local reputation algorithms and inform the creation of synthetic data for simulating attack scenarios. It also seeks to obtain liquidity and slot utilization data to set sane defaults for resource bucketing. A common data export format will be used for analysis. The plan includes collecting anonymized data, propagating an experimental endorsement TLV, and implementing local reputation algorithms. The collaboration of multiple teams ensures a comprehensive approach to the research plan.</summary>
    <published>2023-08-03T08:54:06+00:00</published>
  </entry>
</feed>
