<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>1</id>
  <title>How was the average size of blk*.data chosen?</title>
  <updated>2024-05-31T02:09:53.938665+00:00</updated>
  <author>
    <name>Peter Todd 2024-05-30 18:20:00+00:00</name>
  </author>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>1</id>
    <title>How was the average size of blk*.data chosen?</title>
    <updated>2024-05-31T02:09:53.938702+00:00</updated>
    <link href="https://gnusha.org/pi/bitcoindev/ZljDiesLp29yqipn@petertodd.org/T/#m8b981a0d05aabc1248f5ba2bae142cc46c1811e4" rel="alternate"/>
    <summary>When selecting a number for certain operations, it appears to be a common practice to choose a value somewhat arbitrarily within a broad and acceptable range. The primary consideration for setting an upper limit on values is the compatibility with older file systems, which often do not support files larger than 4GB. This constraint is particularly relevant in scenarios where all block data is stored in a single file, such as with Monero, a cryptocurrency. Storing extensive data in one file can lead to complications when attempting to transfer this file between different locations or systems. 

On the other end of the spectrum, the lower limit is influenced by the technical difficulties associated with managing a large number of files within a single directory. Systems can encounter significant performance issues when tasked with handling tens of thousands of files in one location. These considerations underline the importance of choosing a value that balances the need to avoid exceeding file system limitations while also preventing directory overcrowding.

For further information, insights from Peter Todd can be explored at [https://petertodd.org](https://petertodd.org).</summary>
    <published>2024-05-30T18:20:00+00:00</published>
  </entry>
</feed>
