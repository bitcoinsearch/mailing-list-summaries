{
    "id": "bitcointranscripts+bitcoin-core-dev-tech+2023-04+2023-04-27-fuzzing",
    "title": "Fuzzing",
    "body_formatted": "{\"type\":\"paragraph\",\"text\":\"Slides: <https://docs.google.com/presentation/d/1NlTw_n60z9bvqziZqU3H3Jw7Xs5slnQoehYXhEKrzOE>\"}, {\"type\":\"heading\",\"text\":\"Fuzzing\"}, {\"type\":\"list\"}, {\"type\":\"heading\",\"text\":\"Bug Oracles\"}, {\"type\":\"list\"}, {\"type\":\"heading\",\"text\":\"Best practices for targets\"}, {\"type\":\"list\"}, {\"type\":\"heading\",\"text\":\"Net processing\"}, {\"type\":\"list\"}, {\"type\":\"heading\",\"text\":\"Input splitting\"}, {\"type\":\"list\"}, {\"type\":\"heading\",\"text\":\"Net Processing\"}, {\"type\":\"list\"}, {\"type\":\"heading\",\"text\":\"Bitcoin Core\u2019s Fuzzing Infrastructure\"}, {\"type\":\"list\"}, {\"type\":\"list\"}, {\"type\":\"list\"}, {\"type\":\"heading\",\"text\":\"What next\"}, {\"type\":\"list\"}",
    "body": "Slides: <https://docs.google.com/presentation/d/1NlTw_n60z9bvqziZqU3H3Jw7Xs5slnQoehYXhEKrzOE>\n\n# Fuzzing\n\n- Fuzzing is done continuously. Fuzz targets can pay off even years later by finding newly introduced bugs.\n- Example in slide about libFuzzer fuzzing a `parse_json` function which might crash on some weird input but won\u2019t report invalid json inputs that pass parsing. libFuzzer does coverage guided feedback loop + helps with exploring control flow.\n\n## Bug Oracles\n\n- Assertions - Adding assertions is tricky for network code. We add `Assume()` when continuing is not worse than crashing. `Assert()` will crash in production. `Assume()` will crash in debug. Throwing all kinds of `Assume()` in the code is fine but it slows down production. Place assertions in fuzz target.\n- Resource Limit - Ex: Don\u2019t take more than 10 mb or 5 sec\n- Sanitizers - examples include undefined behaviour, thread, leak, memory, address sanitizers. They can add a performance or memory overhead. Everything except memory sanitizer is easy to use. Recommendation to not use multiple sanitizers at once.\n- Function inverse pairs - encode/decode\n- Differential fuzzing - fuzz current implementation against simpler implementation. Done in coinscache and txrequest.\n- Null space transformation  - only make mutations that preserve semantics\n- Domain specific checks - e.g. bitcoin block under soft fork rule should be valid when no soft fork enforced too\n\n## Best practices for targets\n\n- Avoid non-bug crashes - translate unit tests to fuzz tests (for wallet)\n- Verify coverage - you need to combine information about what function is supposed to do + knowledge about testing.  write target + verify that it reaches code you want to test. Verify coverage using coverage statistics, assert False.\n- Determinism - to identify bugs which naive fuzz test didn't crash so that they\u2019re reproducible. Ideally include fuzz tests in your PR and discriminate between different fuzz targets. Input to fuzzer is not random, it\u2019s just the best possible input. If there is bug, avoid actual randomness - use fixed seeds to mock out randomness.\n- Performance - you spend compute as long as coverage is increasing and if you are maxing out you have to explicitly stop fuzz targets. Fuzzing with sanitisers sometimes gives additional coverage. Sanitisers generally slow you down though. So run corpus with sanitisers as an extra sanity check later. Reset global state at end of each iteration + try to avoid global state. Avoid expensive I/O. Sometimes time is wasted on less interesting input.\n- Keep scope of target small -  Think about what you want to test and focus the fuzzer on that part of the code. Split larger APIs into multiple targets if necessary.\n- Read [fuzzing docs](https://github.com/bitcoin/bitcoin/blob/master/doc/fuzzing.md)\n- Think of writing fuzz targets as if you were writing audits like unit tests, functional tests.\n\n## Net processing\n\n- integration fuzzing? how to address interaction between components using fuzz target/improve some of our integration based fuzzing.\n- When fuzzing net processing, you don\u2019t really care about ping pong going in at same time or validation logic. transaction relay for example. fuzzer gets confused when there is too much information and does lot of unnecessary mutations.\n- `ProcessMessage()` is 1 giant switch statement for the most part - fuzzing for each individual message is included. libFuzzer is not able to produce valid transactions, blocks, headers due to PoW, signatures, hashes etc.. we could/should mock out validation to enable better fuzzing of net processing.\nBoundary testing - not really fuzzing - different technique which is fine to have to new technique to test interactions? You still need to throw wrappers around functions.\n- `txrequest`, `txorphan`, `headerssync` - encapsulate into own modules and test them separately.\nWe want to fuzz net processing in isolation - by doing more refactoring/mocks. some work already but more fixes needed.\n\n## Input splitting\n\n- input splitting - split bytestream into valid c++ data structures.\n- `FuzzDataProvider` - utility to split fuzz inputs into c++ data structures. For example, if you want to fuzz block processing, use `FuzzDataProvider` to parse fuzz inputs into valid blocks.\nwe could write code for producing valid semantics but too much code on test side\n\n## Net Processing\n\n- see <https://github.com/bitcoin/bitcoin/issues/27502>\n- made an issue with all the stuff I want to do if we basically want to fuzz net processing in isolation and mock out the networking side.\n- Position to motivate all refactoring - we don\u2019t hate refactoring. We can turn these red things in net processing into green so that these code regions are covered. That\u2019d be pretty good. This code has found some bugs already.\n- Performance - currently these targets create 1 global instance of chainstate manager etc. but if you want to make the target deterministic then you need to create a new instance of chainstate manager in each iteration and that process currently is very slow. I made a target and it took 10 - 50 exec/sec. In the future, in-memory block storage can be used in tests for better performance.\n- Module separation - I think the module separation between net and net processing has come along pretty well. Almost done - still some work left to do. reviews appreciated. fuzzing seems to be a great motivation for refactoring.\n- Net processing/validation split: Lots of overlap with kernel - that\u2019s going to be a lot of work and hard - haven\u2019t mapped out all things that needs to be done.\n- Speaking of net processing refactors - bug was found in `ProcessMessage()` module. if only motivation is refactoring maybe we shouldn\u2019t. Fuzzing finds bugs - so important too.\n- Refactoring changes need to be accompanied with fuzzing because refactoring often produces bugs.\nWe don\u2019t have a fuzz target that specifically fuzzed version handshake and the branch I have does it and some additional testing for the same. The reason we don\u2019t have version handshake fuzzing is because for peer\u2019s `ProcessMessage()` to work, they need to be initialised.\n- Suggestion to have a document which explains all interfaces introduced when refactoring.\n\n## Bitcoin Core\u2019s Fuzzing Infrastructure\n\n- Contributors run their own fuzzing infra (Marco) + OSS-Fuzz (cluster fuzz instance managed by google)\n- Google donating CPU to open source projects for fuzzing\n\n1. CPU per target per sanitizer per fuzz engine\nhow to contribute inputs back to qa assets? check `--generate` option.\n2. ways to run fuzz test - using empty corpus or corpus from qa-assets repo\nYou clone corpus from qa-assets locally - thing is it gets really big, less than a blockchain :) Github limits qa-asset repo size is a possibility, not a concern currently.\n\n- At branch off time, qa-assets repo is updated. new coverage corpus could be 10-15 GB.\n- Sometimes good to start with an empty corpus which could have additional coverage. working on some code that has a fuzzer associated with it - i\u2019ll run that fuzzer sometimes with an empty corpus strategically - gut feeling - i don\u2019t know good way.\n- Do we delete inputs from the corpus? yes, at branch off.\n- CI fuzz is also done- run on existing seeds for 2 min.\n- Run our own cluster fuzzing instance? not so easy + extra maintenance.\n- Reliance on Google fuzzing infra? we have access to OSS fuzz\u2019s corpus. What if Google kicks us off/not tell bugs. they\u2019ve always told bugs in past incidents. Recently there was an overflow bug in the miniscript\u2019s logic. At that time, i was fuzzing on a 30 core. During that same 24 hour time window, OSS fuzz revealed it too - so an indication that they were honest first.\n- There is a 90 day bug disclosure deadline set by OSS-Fuzz but bitcoin core gets an exception. Never needed and unlikely we find severe bug. So far, we usually find bad bugs while writing new targets and running them on our own infra.\n\n## What next\n\n- Contribute to corpus in qa assets repo which adds additional coverage\n- Reviewing PRs\n- Write fuzz tests\n\n",
    "body_type": "markdown",
    "created_at": "2023-04-27T00:00:00.000Z",
    "domain": "https://btctranscripts.com/",
    "url": "https://btctranscripts.com/bitcoin-core-dev-tech/2023-04/2023-04-27-fuzzing",
    "categories": [
        "core-dev-tech"
    ],
    "tags": [
        "bitcoin-core",
        "developer-tools"
    ],
    "authors": [
        "Niklas G\u00f6gge"
    ],
    "indexed_at": "2024-03-21T16:33:36.020Z",
    "summary": "In the exploration of fuzzing within the realm of software development, Niklas G\u00f6gge provides an insightful overview of its continuous application and the significant benefits it brings to identifying latent bugs within code. Fuzzing, particularly with tools like libFuzzer, employs a coverage-guided feedback loop to delve deep into code paths that might not be thoroughly tested otherwise. This method proves especially effective in parsing functions where unexpected inputs could lead to crashes or unreported invalid outputs, as illustrated in the example involving a `parse_json` function.\n\nThe discussion further delves into the concept of bug oracles, highlighting various strategies to enhance fuzzing efficacy. Assertions play a crucial role in this regard, distinguishing between assumptions permissible in debug modes versus those that would cause a crash in production environments. Moreover, setting resource limits and utilizing sanitizers are recommended practices, albeit with caution regarding their potential overheads. The conversation also introduces more nuanced approaches like function inverse pairs, differential fuzzing, null space transformation, and domain-specific checks, each contributing uniquely to the robustness of fuzz testing routines.\n\nBest practices for crafting fuzz targets are extensively discussed, emphasizing the importance of avoiding non-bug crashes by translating unit tests to fuzz tests, verifying coverage comprehensively, ensuring determinism for reproducibility, optimizing performance, and maintaining a focused scope for each target. These principles are not only vital for effective fuzzing but also serve as guidelines reminiscent of meticulous audit practices akin to writing unit and functional tests.\n\nIn addressing net processing, G\u00f6gge outlines the challenges and opportunities in enhancing fuzzing for network component interactions. By advocating for more modular testing through refactoring and mocking, he underscores the potential for isolating and identifying bugs within complex systems. The segmentation of net processing components such as `txrequest`, `txorphan`, and `headerssync` into distinct modules exemplifies this targeted approach, which could significantly improve fuzzing outcomes by reducing unnecessary mutations and focusing on specific functionalities.\n\nThe utility of input splitting in transforming bytestreams into valid C++ data structures is pointed out as a critical technique for preparing test cases, particularly when dealing with intricate block processing scenarios. This method facilitates a more accurate representation of input data, thereby enhancing the fuzzer's ability to uncover pertinent issues.\n\nReflecting on Bitcoin Core\u2019s fuzzing infrastructure, G\u00f6gge appreciates the collaborative efforts between individual contributors and platforms like OSS-Fuzz. The shared resources and infrastructures play a pivotal role in broadening the scope and depth of fuzz testing across the project. He emphasizes the importance of community contributions to the corpus in the qa-assets repository and the value of reviewing pull requests and writing new fuzz tests as avenues for ongoing improvement and coverage expansion.\n\nIn conclusion, Niklas G\u00f6gge's comprehensive examination of fuzzing practices, from foundational strategies to specific applications within Bitcoin Core, underscores the technique's invaluable role in enhancing software reliability and security. Through continuous evolution and community engagement, fuzzing stands out as a critical tool in the software development arsenal, driving towards more resilient and error-resistant codebases."
}