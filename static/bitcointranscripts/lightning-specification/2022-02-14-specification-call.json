{
    "id": "bitcointranscripts+lightning-specification+2022-02-14-specification-call",
    "title": "Lightning Specification Meeting - Agenda 0957",
    "body_formatted": "{\"type\":\"paragraph\",\"text\":\"Name: Lightning specification call\"}, {\"type\":\"paragraph\",\"text\":\"Topic: Agenda below\"}, {\"type\":\"paragraph\",\"text\":\"Location: Jitsi\"}, {\"type\":\"paragraph\",\"text\":\"Video: No video posted online\"}, {\"type\":\"paragraph\",\"text\":\"Agenda: <https://github.com/lightning/bolts/issues/957>\"}, {\"type\":\"heading\",\"text\":\"Organizing a Lightning Core Dev meetup\"}, {\"type\":\"paragraph\",\"text\":\"I was talking about organizing a face to face Lightning Core Dev meetup. If I understand correctly there has only been one formal one and that was in 2019 in Australia. There has been two?\"}, {\"type\":\"paragraph\",\"text\":\"Milan, the kickoff. There has only ever been two.\"}, {\"type\":\"paragraph\",\"text\":\"That was probably before my time in Bitcoin.\"}, {\"type\":\"paragraph\",\"text\":\"We get to Bora Bora? Did that come up on the list?\"}, {\"type\":\"paragraph\",\"text\":\"I think it is high time that we meet in person. I know there was one last fall but Rusty couldn\u2019t travel and a bunch of folks couldn\u2019t. Let\u2019s try to get one organized that has as good a participation as possible from the Lightning spec developers. If anyone has questions we can discus right now. I just wanted to give a heads up. I plan to send a survey out just to get some sense for locations and dates that work for folks. It will probably be impossible to accommodate everyone but I\u2019ll do my best to take that information and find a way to get something scheduled in the next few months. I suspect it will be April, May timeframe. I am going to try to make it work, at least by May. Something that works for everyone. Are there any quick questions or things I should be thinking about when trying to organize this? I\u2019ve organized a couple of Core Dev meetups in the past, we\u2019ll take lessons and learnings from that. As they develop we\u2019ll reveal plans and get feedback from everyone to make sure it is as valuable as possible.\"}, {\"type\":\"paragraph\",\"text\":\"There are a few things popping up randomly that maybe people will be at. I know some people are going to be in London, some people may be in Miami. If we can piggy back maybe that can work but London is in like 3 weeks.\"}, {\"type\":\"paragraph\",\"text\":\"I\u2019m probably the only Lighting one but I\u2019m not going to the UK. I know a number of Core devs aren\u2019t going to the UK either.\"}, {\"type\":\"paragraph\",\"text\":\"Some of our people are going but they are already in Europe, it is a skip. Not a long distance.\"}, {\"type\":\"paragraph\",\"text\":\"I\u2019m happy to go to Europe. Because of the lawsuit currently entering into the UK\u2026 At least until we finish the jurisdiction challenge.\"}, {\"type\":\"paragraph\",\"text\":\"I forgot that was happening in the background.\"}, {\"type\":\"paragraph\",\"text\":\"As these Bitcoin conferences occur, some subset of us there, let\u2019s meet up and make progress. Work towards to this one where the majority of us can hopefully attend.\"}, {\"type\":\"heading\",\"text\":\"Use warning message in quick close\"}, {\"type\":\"paragraph\",\"text\":\"<https://github.com/lightning/bolts/pull/904>\"}, {\"type\":\"paragraph\",\"text\":\"This is a one liner to use a warning. This should be easy to integrate. Another thing that we could discuss about that PR is the point Laolu raised. We could add a feature bit for that. I don\u2019t think we need to and I think Matt doesn\u2019t think we need to either.\"}, {\"type\":\"paragraph\",\"text\":\"If this thing can save you a bunch of chain fees maybe you want to find people that promise to always do it. That was the rationale there. Otherwise you have the fallback thing. Maybe you end up paying more because they are doing weird stuff. I started implementing this, I need to go back to my PR.\"}, {\"type\":\"paragraph\",\"text\":\"We can separately discuss having a feature bit for the quick close thing itself. But this in general is just adding an extra warning message on the wire. I don\u2019t know why we would add a feature bit for just that.\"}, {\"type\":\"paragraph\",\"text\":\"People send warnings today. I get some issues in lnd, an unknown thing. Maybe we should add more logic in there basically. I think c-lightning sends one if you already have a channel that is closing and you try to do a new one. I think Carla has an older PR for that, we just need to revive it so we can see when things are going wrong.\"}, {\"type\":\"paragraph\",\"text\":\"I think we send them too now. It is just a new message type that you are supposed to log.\"}, {\"type\":\"paragraph\",\"text\":\"We had an older PR that was waiting for stuff to settle down but it is merged now so we could move forward with that. I\u2019m trying to find it now.\"}, {\"type\":\"paragraph\",\"text\":\"I agree it is completely orthogonal to a feature bit so maybe have a quick look at that PR.\"}, {\"type\":\"heading\",\"text\":\"Offers\"}, {\"type\":\"paragraph\",\"text\":\"<https://github.com/lightning/bolts/pull/798>\"}, {\"type\":\"paragraph\",\"text\":\"We\u2019ve been working a lot on offers on eclair recently. It is making steady progress. I put one comment on the PR about blinded paths in the `payinfo` but apart from that I don\u2019t think there\u2019s much to discuss on our side.\"}, {\"type\":\"paragraph\",\"text\":\"I did the classic pre-meeting \u201cI should do something\u201d. I went through and applied a few changes, a few typos and things. There was a compat break that I have implemented with compat mode. We seem to be pretty close. I look forward to seeing how interop goes once you\u2019ve got that working. There was a request from Matt. We\u2019ve got blinded paths but we don\u2019t have simple route hints. The problem is you can\u2019t pay via a blinded path until we\u2019ve got the pay via blinded path stuff. He was wanting this shim that I\u2019m reluctant to do but it is practical. I can give you a single unblinded hop. We hold our nose and implement for now. Then eventually it will be in the wonderful unicorn, flying car days and we\u2019ll have full blinded payments and we can get rid of it.\"}, {\"type\":\"paragraph\",\"text\":\"To be clear I am not going to agitate strongly for this. I think it would let us deploy a little quicker. Obviously we would deprecate it within a year. Then we would remove it another year. But if the answer is no I am definitely not going to advocate very strongly for this and push back. I leave it up to you.\"}, {\"type\":\"paragraph\",\"text\":\"I need to dive a bit more into that. I do not realize yet how much work I will have to do. I would be able to know more in a few weeks and then make a recommendation. Right now I suggest to keep it in until we realize that it is too much and we want to ship without it. Then we may want to remove it. I added a comment today which is potentially another breaking thing so you may want to take a look at it. It is about using a single blinded hint for the whole blinded path instead of one per hop. That is something that would change the wire requirements. We need to decide whether we want to do it or not. While I was reviewing Thomas\u2019 PR on eclair to add offers I realized that there this thing which is a routing hint saying how much fees and CLTV delta to use for the parts of the blinded path. Thomas understood it as there must be one for every hop in every blinded path that is in the offer or the invoice. The way I understood it was we only need one per path and we should apply the same fee and CLTV for all hops in the path to hide them more. You don\u2019t want to show there are different fees here. That is an unblinding vector and it takes up less space.\"}, {\"type\":\"paragraph\",\"text\":\"You still have to indicate the number of hops though.\"}, {\"type\":\"paragraph\",\"text\":\"Yeah. You still have to have an unencrypted blob for each of the hops. But for the fees and CLTV you just provide one value that should work for all the hops in that route. It is more lightweight in the offer and in the invoice. Especially if you add dummy hops at the end of the blinded route you don\u2019t have to repeat new fees and CLTV expiry that takes up more space for no reason. It also forces you to have something that is uniform and works for the whole path which makes it hopefully harder to unblind.\"}, {\"type\":\"paragraph\",\"text\":\"Does that mean you have to go through all the nodes across all the different payment paths, find the one which is charging the highest fees and apply that ubiquitously to every single node?\"}, {\"type\":\"paragraph\",\"text\":\"In a way that is already what you do. When you include the path you have all the data for all these hops so you just select the highest fee instead of selecting the right fee for each of the hops.\"}, {\"type\":\"paragraph\",\"text\":\"If you are doing something smart you obfuscate those numbers. It doesn\u2019t help a huge amount because they can still probe. We have a plan for that, that\u2019s later. You put something inside the onion to say \u201cDon\u2019t accept below this fee because they are trying to use it to probe you.\u201d It is not a break for me because I don\u2019t write this field at the moment. We can certainly change it. It is a simplification, it makes sense. You could imagine a case where I am feeding you a blinded path where one is higher. You could argue if it is such an obvious vector then don\u2019t put that in the blinded path, start with the blinded path after that.\"}, {\"type\":\"paragraph\",\"text\":\"Or just use the higher value for everyone. One other thing I was arguing in the route blinding PR is that it may be frightening for the sender to see that there is a high fee to pay for the blinded part of the route. But actually you could reverse that and make it be paid by the merchant. The merchant would discount the value of the real item and would actually pay for the fee of the blinded path himself because it makes sense. The merchant is trying to hide themselves so they should pay the fee for the blinded part of the route.\"}, {\"type\":\"paragraph\",\"text\":\"I buy the argument. If you are paying for liquidity you will end up with this one hop that is potentially significantly higher. But at the moment the Lightning Network is still low. I ACK that, I will write some verbiage around it. Change it to a single that applies across the route, I like it.\"}, {\"type\":\"heading\",\"text\":\"Zero conf channels\"}, {\"type\":\"paragraph\",\"text\":\"Previous discussion: <https://btctranscripts.com/lightning-specification/2021-11-22-specification-call/#simple-turbo-channels-enablement>\"}, {\"type\":\"paragraph\",\"text\":\"We have a pretty comprehensive implementation of it but there was that one thing that we left, the channel type or not. Maybe here I can explain our use case or flow versus the reject on accept. For me it is a fail early versus fail after they send you a non-zero value on min depth. In our case, people like Breez are already doing zero conf channels today. If Breez is starting to use Pool to acquire a zero conf channel for onboarding, in our case we have a channel acceptor that looks at the order in Pool and says \u201cThis is not the channel type, we reject.\u201d With this we need a channel acceptor acceptor. Whenever someone sends you an accept message you need to have that hook there. We already have a pre-accept hook versus a post-accept one. Adding the channel type here would let us know if they are actually going to do the thing. Some people commented that they could do whatever anyway but at least we have that first protection. You can say \u201cThey can do that in any case but the protocol is what we expect. The extraneous stuff can be handled on the side.\u201d We have a full implementation. We should probably test some stuff on the side. That\u2019s the one thing. We want a channel type so we can at least say \u201cI want to open a zero conf channel to you\u201d. Whereas right now this is saying \u201cI will allow you to do zero conf after it is extended\u201d. That is a slightly different flow.\"}, {\"type\":\"paragraph\",\"text\":\"Don\u2019t you already have some kind of hooks on the accept channel message? There\u2019s tonnes of fields in the accept channel message that users will presumably want to filter on?\"}, {\"type\":\"paragraph\",\"text\":\"The way we handle it, depending on how you do it, you either have a function closure that tells you what to post to the other party\u2026 Up until now there has never been a need to do anything on accept channel. Whenever someone sends you an `open_channel` message that\u2019s when you\u2019d say \u201cI only want private channels. I don\u2019t support this feature bit. They have a green alias, I don\u2019t like that.\u201d That is what people use pretty widely today.\"}, {\"type\":\"paragraph\",\"text\":\"You said on receiving `open_channel`? These are two different directions. You mean before you send `open_channel`?\"}, {\"type\":\"paragraph\",\"text\":\"Us and other implementations have something like a channel acceptor when you receive `open_channel`. You are saying \u201cDo I want to accept this channel since the default things are currently one way?\u201d\"}, {\"type\":\"paragraph\",\"text\":\"Let\u2019s separate the conversation between outbound and inbound channels.\"}, {\"type\":\"paragraph\",\"text\":\"I\u2019m concerned with accepting. Let\u2019s say Breez acquired a channel for their user, a node on the network is now opening a channel to your mobile.\"}, {\"type\":\"paragraph\",\"text\":\"So it is an outbound channel?\"}, {\"type\":\"paragraph\",\"text\":\"Yes it is an outbound channel. The way it is setup, the maker is always the one that is going to be opening the channel, in this case the person who is opening the zero conf channel. Right now in our flow the user would see the `open_channel`, assuming there is a channel type and whatever else, see it is not zero conf and then reject it. Otherwise it would need to accept it and then later on have an exception down the line that they send a `min_depth` of a different value. That\u2019s the flow.\"}, {\"type\":\"paragraph\",\"text\":\"You flipped it on us again. You are talking about the side that is accepting the channel, not the channel opener. And you want to filter on the `open_channel` message itself.\"}, {\"type\":\"paragraph\",\"text\":\"Yes. We do a similar thing. If someone wants anchor only because we have a feature bit or a channel type there, they can say \u201cThat\u2019s not an anchor channel. I\u2019m rejecting it\u201d and everything moves forward like that. I don\u2019t see a reason not to add a channel type here if it can make peering and general protocols built on top of it more explicit. We can fail quicker rather than failing later. The failing later, we would receive the `min_depth`\u2026\"}, {\"type\":\"paragraph\",\"text\":\"You said this is for the case where a user has received an `open_channel` and then is going to make some decision based on that `open_channel` and then send a response or an `accept_channel`. But once you\u2019ve received that `open_channel` you now have all the information. The `min_depth` is only in the `accept_channel`. Presumably the node that is opening the channel, if you tell it it is zero conf it is just going to accept that because why wouldn\u2019t it? In my understanding of the way we\u2019ve done it and c-lightning has spoken about implementing it just seeing the `open_channel` and knowing what you are going to write in the `accept_channel` is sufficient to know whether the channel will be zero conf.\"}, {\"type\":\"paragraph\",\"text\":\"That\u2019s the difference. Y\u2019all are saying zero conf all day everyday. We are saying zero conf under these very precise scenarios. It wouldn\u2019t be a default thing for the world. I don\u2019t see any downside and I feel like it makes certain protocols more precise because you can fail earlier. We have a lot of feature bits, we already have a channel type here too. Maybe certain channels can\u2019t support zero conf in the future.\"}, {\"type\":\"paragraph\",\"text\":\"And multi funder is a whole other discussion.\"}, {\"type\":\"paragraph\",\"text\":\"We have the ability at the protocol level to allow that filtering to exist in the future by having the zero conf bit here.\"}, {\"type\":\"paragraph\",\"text\":\"In the case of you\u2019ve received an `open_channel` message, you say \u201cI\u2019m going to do zero conf with this channel\u201d. Presumably at that point you\u2019ve done further out of band negotiation. Obviously you are not going to accept zero conf from anyone, you are going to say \u201cThis node, we\u2019ve already negotiated this and that\u201d. Why can that negotiation not be the thing that decides this instead of having it be a negotiation? First you negotiate, you know you are going to do zero conf with this node, you get a channel from that node and then you do an additional negotiation step and say \u201cIt must be zero conf\u201d.\"}, {\"type\":\"paragraph\",\"text\":\"This is when things are extended. At that point maybe they are eligible. But in this case whenever you send it I know it is there at runtime. We always try to verify the lowest layer. Let\u2019s say we are doing this thing and it is not in the feature bit. Then the user sends `min_depth` zero, for whatever reason other party says \u201cNo\u201d. At that point you have a weird silent failure. Now the receiver is saying \u201cZero conf\u201d rather than the proposer. If the proposer initially gets the `accept_channel` and then does nothing, UX wise it is hard to have a consistent flow there.\"}, {\"type\":\"paragraph\",\"text\":\"I don\u2019t understand why. You\u2019ve already negotiated it. The initiator and the acceptor has negotiated it. The acceptor says \u201cYes zero conf\u201d and now the initiator is like \u201cActually no, not zero conf\u201d. Then you\u2019re saying \u201cThe UX is going to be confused.\u201d Of course the UX is confused, the initiator is buggy.\"}, {\"type\":\"paragraph\",\"text\":\"If we have a flow here where we know the initiator is doing a weird thing from the beginning we are able to make things a lot more consistent. The way it works, we ignore them, we do matching again and we can proceed. While with this one it is a weird indeterminate thing.\"}, {\"type\":\"paragraph\",\"text\":\"The channel now has to wait for a few confirmations. So what?\"}, {\"type\":\"paragraph\",\"text\":\"But now the user\u2019s expectation is trashed. \u201cI thought I was getting a zero conf channel. I can\u2019t use it at all. Is the wallet broken?\u201d\"}, {\"type\":\"paragraph\",\"text\":\"It is the user\u2019s fault.\"}, {\"type\":\"paragraph\",\"text\":\"It is not the user\u2019s fault. It is the protocol not being able to surface and allow things to be explicit like this. Can you explain the cost of adding a channel type feature bit here? In the future maybe certain channel types aren\u2019t zero conf friendly at all. We are able to add a provision for that from the get go versus in the future realizing that the `min_depth` dance isn\u2019t sufficient for whatever new super Taproot covenant channel type people come up with.\"}, {\"type\":\"paragraph\",\"text\":\"I am just trying to understand exactly the differences here in terms of the flow.\"}, {\"type\":\"paragraph\",\"text\":\"The UX is inconsistent because after everything is under way things can break down. Versus just saying \u201cWe\u2019ve checked at the beginning. You have the `open_channel` rejected there.\u201d Then we can at least say \u201cWe weren\u2019t able to find a match for you\u201d versus \u201cWe\u2019ve found a match but then it turned out to be a counterfeit good basically\u201d. It is like buying a car, they told you it was manual and it is automatic. You are like \u201cWhat is this? I can\u2019t drive this thing.\u201d That\u2019s a framing. It is making sure the user is buying or selling the good as much as we can validate it upfront.\"}, {\"type\":\"paragraph\",\"text\":\"The problem with this PR is it conflicts two things. One is if you do zero conf you need some alias mechanism, you need a name for it before it is confirmed. That\u2019s almost useful. We\u2019ve decided we like that. Whether you are doing zero conf or not it is nice to have this alias facility, private channels and stuff like that. That\u2019s almost a PR by itself. The problem with zero conf is if you say \u201cYes I want a zero conf channel\u201d are you committing to trusting them with the channel? I can open a zero conf channel and let you open it and pretend and then never forward anything until it is confirmed. But presumably when you\u2019ve said \u201cI want a zero conf channel\u201d you are all in and ready to trust with this. Or you are on the side that doesn\u2019t require trust. That is what you are trying to signal.\"}, {\"type\":\"paragraph\",\"text\":\"One other slight thing here with the way Pool works, we like this because it increases the set of signers required to double spend. For example if I have a batch of 5 people opening a channel it requires all 5 of them to double spend rather than just the person that was opening. It also requires us to double spend as well too. It increases the total set of collusion that is necessary in order to double spend the output. The reason they can\u2019t double spend is they are in a UTXO that is a 2-of-2 with us. They would need us and every other person as well to double spend the entire batch. That\u2019s the one difference security model wise with how this works in this setting. It is like a coinjoin where everyone has a timelocked input basically. The input will only be signed if things look good. The trust stuff is explicit. That\u2019s another reason to add a channel type there. \u201cDo I want to accept this zero conf thing?\u201d You are right that there is a double opt-in. We are just trying to make it more explicit. It is more sensible if we know zero conf stuff can\u2019t work for every channel type.\"}, {\"type\":\"paragraph\",\"text\":\"Originally the channel types were just to get around this hack. There were some features we had to remember. If you negotiated that at the beginning that made sense for the whole channel lifetime independent of what\u2019s in the future. But generalizing it to \u201cThis is not persistent state but this is stuff about this channel\u201d. It is not objectionable.\"}, {\"type\":\"paragraph\",\"text\":\"If we want explicit signaling I would strongly suggest we switch to a TLV in `open_channel` rather than making it a channel type.\"}, {\"type\":\"paragraph\",\"text\":\"That\u2019s exactly what we have. We have a TLV that is a channel type in `open_channel`.\"}, {\"type\":\"paragraph\",\"text\":\"Internally from the architecture, when we switched across I just went through and changed everything to channel types internally. It was so much nicer. Instead of all these adhoc things going \u201cIs this an anchor channel? Is this a static remote key channel?\u201d suddenly became this bit test of the channel type, this field that went all the way through.\"}, {\"type\":\"paragraph\",\"text\":\"For us it allows us to move our implementation closer to the protocol. We already had the channel type before but now it is one-to-one. It is a different enum or whatever but same thing.\"}, {\"type\":\"paragraph\",\"text\":\"In retrospect we should have done this originally. There are two things. One is do you get an alias? I think the answer is everyone wants an alias. You need an alias if you are doing the zero conf thing obviously. But the way the spec was written is that you\u2019ll get one. I think this is nice. I am actually not all that happy with a channel type the more I think about it. But I do want to go and implement it and see what that does.\"}, {\"type\":\"paragraph\",\"text\":\"It does feel weird because channel type is all stuff that is only persistent.\"}, {\"type\":\"paragraph\",\"text\":\"It is today but maybe that is inflexible thinking. My only caveat on this, it is not necessarily a huge issue, you open a channel and you go \u201cI expected that to be zero conf\u201d. You can specify that afterwards. We were going to have an API where you could go \u201cTrust this node ID\u201d. Obviously if you open a new channel it would be zero conf but you could also zero conf an existing channel by going \u201cI\u2019m going to start ACKing it\u201d. Assuming that it had support for the alias so you were ready to do that. You would end up with a zero conf but you would never have signaled a zero conf. I guess you are free to do that.\"}, {\"type\":\"paragraph\",\"text\":\"Presumably the way y\u2019all would implement that is that even if your counterparty says \u201c6 confs\u201d you will always send the `funding_locked` immediately after you broadcast the funding transaction if you are the initiator. Is that what you are thinking?\"}, {\"type\":\"paragraph\",\"text\":\"Yeah. If you are the initiator and there is no `push_msat`. And in our case with dual open, if you\u2019ve got no funds on the line we will just go \u201cSure whatever\u201d, we will zero conf stuff.\"}, {\"type\":\"paragraph\",\"text\":\"Why does `push_msat` matter?\"}, {\"type\":\"paragraph\",\"text\":\"If I have all the funds in the channel then I can use the channel immediately. If you screw me you\u2019ve just lost money. But if I\u2019ve `push_msat` to you you can push stuff through the channel.\"}, {\"type\":\"paragraph\",\"text\":\"You are still presumably not going to double spend yourself. It just prevents you from double spending the funding transaction? The idea is that you\u2019d like to be able to continue double spending the funding transaction? The initiator pushes msat to the other counterparty, it is all your funds but you\u2019ve given it to the initiate key?\"}, {\"type\":\"paragraph\",\"text\":\"Specifying `push_msat` puts you at some risk of them getting the money. If it is single conf even if your double spend fails you still have everything.\"}, {\"type\":\"paragraph\",\"text\":\"Presumably you were ok with them getting the money because you\u2019ve pushed msat to them?\"}, {\"type\":\"paragraph\",\"text\":\"If you wanted to scam them maybe you wouldn\u2019t do that.\"}, {\"type\":\"paragraph\",\"text\":\"The guy who accepts the `push_msat`, if it is a payment for something that has been semi trusted and done before, \u201cI will push you msat because I opened this channel because you opened a channel to me. I opened a channel back in response. I will push you money through that.\u201d But if you accept it as zero conf and they double spend it you lost that msat, maybe you opened a channel in response. It is more the guy who accepts the `push_msat` that has a risk of accepting zero conf.\"}, {\"type\":\"paragraph\",\"text\":\"You can generalize this for the dual funding case.\"}, {\"type\":\"paragraph\",\"text\":\"This is an interesting question then. Basically the channel type or TLV or whatever would say \u201cEither send me an accept with zero `min_depth` or I\u2019m going to immediately close the channel.\u201d\"}, {\"type\":\"paragraph\",\"text\":\"Or send a warning message or error and whatever else.\"}, {\"type\":\"paragraph\",\"text\":\"The initiator will still always send a `funding _locked` immediately and the receiver can still send a `funding_locked` immediately if they want to. The feature bit is only an indicator of either you do this or I am going to close the channel.\"}, {\"type\":\"paragraph\",\"text\":\"It should also indicate that you have some degree of trust, that you will route. I could send whatever I want across the wire and not consider the channel open until\u2026 I think it should imply that you are going to let them do zero conf.\"}, {\"type\":\"paragraph\",\"text\":\"They can just deny any channel that has this set. Maybe that helps, maybe that doesn\u2019t. They at least have that ability.\"}, {\"type\":\"paragraph\",\"text\":\"The thing is it should flag that they are trusting the zero conf, not just that they are walking through the protocol.\"}, {\"type\":\"paragraph\",\"text\":\"It should say that they must, not just that they can. If you see this bit and you are going to send an `accept_channel` that does not have a zero conf `min_depth` you must fail the channel.\"}, {\"type\":\"paragraph\",\"text\":\"Negotiation has failed at that point.\"}, {\"type\":\"paragraph\",\"text\":\"It is not optional.\"}, {\"type\":\"paragraph\",\"text\":\"On the alias being decoupled, do we like that in the same combo still? The alias thing has a feature bit already right?\"}, {\"type\":\"paragraph\",\"text\":\"Yes.\"}, {\"type\":\"paragraph\",\"text\":\"You must only route through this bit, not there is an alias offered. The feature bit is not just for the alias itself.\"}, {\"type\":\"paragraph\",\"text\":\"The feature bit is weird. It is like \u201cOnly use this one. I really understand what I\u2019m doing and I only want you to use this. Discard the real short channel ID.\u201d This is kind of what you want. But whether we should use a different feature bit for that, I am going to have to look back. We do want a way to say \u201cI am all in on this whole alias idea.\u201d\"}, {\"type\":\"paragraph\",\"text\":\"It should be all or nothing.\"}, {\"type\":\"paragraph\",\"text\":\"But for backwards compat or \u201cI don\u2019t care. It is going to be a public channel but it is zero conf for now\u201d I can use an alias and then throw it away. This is where the alias becomes a bit schizophrenic. We\u2019ve got these two roles. The feature bit would say \u201cWe\u2019re all alias and we are only alias\u201d. It is kind of overloaded. Maybe we should go back and change the bit number. If I switch it to a channel type I\u2019ll see what happens.\"}, {\"type\":\"paragraph\",\"text\":\"I thought you did switch it to a channel type.\"}, {\"type\":\"paragraph\",\"text\":\"That is a channel type. Because that is something you have got to remember forever. The same bit would be used for the other channel type so now I have to find another one.\"}, {\"type\":\"paragraph\",\"text\":\"I think it is an example of the advantage of the feature bit. You can have these as individual things. Zero conf and the alias only or you can have all of them. That\u2019s nice in terms of the bit vector comparison thing.\"}, {\"type\":\"paragraph\",\"text\":\"This is where I\u2019m coming around to they are separate things.\"}, {\"type\":\"paragraph\",\"text\":\"A different feature bit.\"}, {\"type\":\"paragraph\",\"text\":\"Yes. Part of the roadblock that we got is because we put them both in together. It became this logjam.\"}, {\"type\":\"paragraph\",\"text\":\"Zero conf requires aliasing though yes?\"}, {\"type\":\"paragraph\",\"text\":\"In order to receive before confirmed yes but maybe we don\u2019t care about that eventually.\"}, {\"type\":\"paragraph\",\"text\":\"Yes. If you don\u2019t have an alias then all that can happen is they can push sats through you but you can\u2019t use the channel.\"}, {\"type\":\"paragraph\",\"text\":\"It is kind of useless without that. Does that mean that you intend to split this PR into two? Or are we going to continue? It sounds like LND already has an implementation, LDK has one.\"}, {\"type\":\"paragraph\",\"text\":\"We have one of everything. The only divergence is the upfront feature bit check. I am cool with keeping it as is and we maybe throw out the bits. Once we have that squared up we can look at cross compat testing.\"}, {\"type\":\"paragraph\",\"text\":\"Add a TLV rather than defining a new bit.\"}, {\"type\":\"paragraph\",\"text\":\"We have a TLV.\"}, {\"type\":\"paragraph\",\"text\":\"Add a TLV that says the required bit.\"}, {\"type\":\"paragraph\",\"text\":\"I\u2019ll edit this PR for now. If I was smarter I\u2019d have split it into two. I don\u2019t think it is worth splitting now.\"}, {\"type\":\"paragraph\",\"text\":\"It is pretty small, not a multi file mega thing.\"}, {\"type\":\"paragraph\",\"text\":\"Action Rusty to do another pass, make a channel type and see what happens, how bad it gets.\"}, {\"type\":\"heading\",\"text\":\"Zero reserve\"}, {\"type\":\"paragraph\",\"text\":\"I\u2019m going to jot that down on the PR. One other thing related to this is zero reserve. Eugene is implementing this and asking questions about zero reserve. Right now I let you cheat me for free but maybe it is not useful unless we have it both ways. I think he was wondering do you always do zero reserve? I think right now technically if you send zero it is in violation of the spec. I think we have must be greater than zero thing.\"}, {\"type\":\"paragraph\",\"text\":\"We accept it, we do not allow you to send it currently. We may at some point allow you to send it. We accept it, maybe in violation of the spec.\"}, {\"type\":\"paragraph\",\"text\":\"Must set greater than or equal to `dust_limit_satoshis`.\"}, {\"type\":\"paragraph\",\"text\":\"If you set that to zero there is that weird interaction. I looked at a really old Breez PR, I found that it allowed zero reserve but it didn\u2019t because it would reject it if it was less than the dust limit. We also had some dust limit revelations a few months ago as far as interactions with other fields.\"}, {\"type\":\"paragraph\",\"text\":\"At least in our codebase I don\u2019t think there\u2019s a weird interaction. If the output value is less than the dust limit you still have to remove it.\"}, {\"type\":\"paragraph\",\"text\":\"Otherwise you\u2019d have a weird situation where I make the reserve on your commitment transaction below dust which means it can\u2019t propagate. Maybe I can do that by rebalancing or something like that.\"}, {\"type\":\"paragraph\",\"text\":\"There is still a `dust_limit_satoshis`.\"}, {\"type\":\"paragraph\",\"text\":\"The issue is you can end up with a zero output transaction.\"}, {\"type\":\"paragraph\",\"text\":\"As long as your dust limit is non-zero. You still remove the output.\"}, {\"type\":\"paragraph\",\"text\":\"No you remove all the outputs, that\u2019s the problem. That\u2019s not a valid transaction.\"}, {\"type\":\"paragraph\",\"text\":\"A zero output transaction, I see your point.\"}, {\"type\":\"paragraph\",\"text\":\"By forcing a reserve you are saying that someone has an output at all times. I think that was the corner case that we ended up slamming into. Maybe it doesn\u2019t matter. What are you doing with your life if you\u2019ve managed to turn everything into dust? I don\u2019t if that is real but I remember that corner case.\"}, {\"type\":\"paragraph\",\"text\":\"I know Breez is running a LND fork and they already doing this in the wild.\"}, {\"type\":\"paragraph\",\"text\":\"If the other guy lets you have zero reserve on your side it is all a win for you. It is only for the other guy that it is a risk.\"}, {\"type\":\"paragraph\",\"text\":\"Exactly. If you say I can have zero I\u2019m fine with that. That doesn\u2019t necessarily give you what you want. You want to be able to do \u201csend all\u201d, close the app and walk away. But right now people have that weird change value lingering. I\u2019m not sure how the mobile apps handle it in practice.\"}, {\"type\":\"paragraph\",\"text\":\"That\u2019s why we did zero reserve on Phoenix, to be able to do \u201csend all\u201d and to have users send all of their balance out, there is nothing remaining.\"}, {\"type\":\"paragraph\",\"text\":\"Because otherwise it is weird. You have this value you can\u2019t move and people will get frustrated about that.\"}, {\"type\":\"paragraph\",\"text\":\"We had users who were like \u201cNo I need this or I can\u2019t ship\u201d. I think we have separate dust enforcement around our outputs. That\u2019s a good point, there may be a corner case where you could hit a zero output transaction.\"}, {\"type\":\"paragraph\",\"text\":\"That was the killer. It is unspendable. In one way you don\u2019t care, on the other hand it is UTXO damage.\"}, {\"type\":\"paragraph\",\"text\":\"It is application level brain damage at that point.\"}, {\"type\":\"paragraph\",\"text\":\"So this is one of those more investigation required things?\"}, {\"type\":\"paragraph\",\"text\":\"Write in the spec what you do if you end up in this case. Or figure out a way to avoid it. Say that \u201cThe minimum channel size must be such that you can\u2019t be all dust\u201d. Though that isn\u2019t actually possible because your HTLC dust limit depends on your fee rate and stuff like that.\"}, {\"type\":\"paragraph\",\"text\":\"If it is only when anchor outputs, zero fee is used then you have no risk. There is no trim to dust, it is only the dust limit on HTLCs. If your channel is not really small you will always have outputs in there.\"}, {\"type\":\"paragraph\",\"text\":\"What do you mean there is no dust? What if we just move the reserve to the anchor output? Maybe that would solve it.\"}, {\"type\":\"paragraph\",\"text\":\"He\u2019s two steps ahead. I was suggesting that you make your channel size such that you can never have it all dust. But that is not possible in a classic channel because your HTLC size that gets trimmed depends on your fee rate. But as he\u2019s saying, that is not true with zero fee HTLC anchors. Modern anchors, that is not true anymore. You could just figure out what the number is and don\u2019t have a channel smaller than this and you can have zero reserve. Maybe that\u2019s the answer.\"}, {\"type\":\"paragraph\",\"text\":\"Can you explain the making sure you never have dust? You mean you have a minimum channel size that is just above dust?\"}, {\"type\":\"paragraph\",\"text\":\"To avoid this problem where you end up with zero outputs because everything is dust, if you blow away the reserve requirement, you could fill it with enough HTLCs that are all dust. Suddenly you have got zero outputs. You want to avoid that. Figure out what the numbers are. It depends on the max number of HTLCs and your dust limit. But it no longer depends on the fee rate which was the impossible one. If you put that as a requirement, you\u2019ve got to have modern anchor and you\u2019ve got to have larger than this number, formula whatever, then you can have zero reserve. I think that covers the corner case.\"}, {\"type\":\"paragraph\",\"text\":\"You could probably also get away with that Antoine PR that is overly specific. Presumably at this point every implementation has their own separate dust limiting functionality and you could also lean on that depending on how you implemented that. Maybe that is too weird.\"}, {\"type\":\"paragraph\",\"text\":\"It seems like anchors makes it possible for you to compute what this minimum channel size should be to make sure nothing is ever fully dust. You always have enough funds left over after paying for the fees of HTLCs, the first level output that is.\"}, {\"type\":\"paragraph\",\"text\":\"Independent of fee rate which is nice.\"}, {\"type\":\"paragraph\",\"text\":\"There is still one edge case. If the fee rate goes really, really high and you are not capping it because of anchor. If you don\u2019t have any HTLCs and the fee rate goes to the roof\u2026 there is only one guy paying the fee\u2026\"}, {\"type\":\"paragraph\",\"text\":\"As long as that guy paying the fee is the one with all the balance and the other one has rounds to dust.\"}, {\"type\":\"paragraph\",\"text\":\"It is possible in theory, yeah.\"}, {\"type\":\"paragraph\",\"text\":\"You may have to put a clause in the fee rate saying you don\u2019t do that. \u201cDon\u2019t set a fee rate such that you would end up with zero outputs\u201d. Figure out exactly what to test rather than just saying that. Assuming we can work out why are we suggesting this is a new channel type? A zero reserve channel type?\"}, {\"type\":\"paragraph\",\"text\":\"I don\u2019t see why it would be.\"}, {\"type\":\"paragraph\",\"text\":\"The argument is \u201cThis is the kind of channel I want\u201d.\"}, {\"type\":\"paragraph\",\"text\":\"It would be the exact same reasoning of the previous discussion. They can always send it and presumably you negotiated it in advance.\"}, {\"type\":\"paragraph\",\"text\":\"Similar thing. This would give them the level of guarantee they have today. But more broadly in the network. By them I mean people like Muun and Breez that already do it.\"}, {\"type\":\"paragraph\",\"text\":\"It is one of those things that are pre-negotiated.\"}, {\"type\":\"paragraph\",\"text\":\"That does touch on what Lisa is doing on dual funding. On dual funding she says that the reserve is not negotiated, it is only a percentage. There is a boolean saying \u201cInclude it or not include it\u201d. You decide it at what step exactly? In which message? I don\u2019t remember.\"}, {\"type\":\"paragraph\",\"text\":\"I don\u2019t think I have added the boolean thing yet. We\u2019ve talked about adding it.\"}, {\"type\":\"paragraph\",\"text\":\"At the moment it is 1 percent. The 1 percent is known at negotiation time, you choose the protocol you are using. I haven\u2019t added the boolean thing yet.\"}, {\"type\":\"paragraph\",\"text\":\" Even if we had the boolean it would be after discussing the channel types. So maybe it would be the same thing as for zero conf. If we want to know it upfront then we do need a channel type.\"}, {\"type\":\"paragraph\",\"text\":\"I think it makes sense as a channel type. It also is a feature bit. You know what you are getting. The reason I like 1 percent reserve is the same kind of reason. I could tell you exactly what channel size you will have after putting in this many sats. If we make it a channel type it falls automatically into dual funding anyway.\"}, {\"type\":\"paragraph\",\"text\":\"Does anybody know if you can get zero outputs with just one side sending zero channel reserve? Because there\u2019s an asymmetry here?\"}, {\"type\":\"paragraph\",\"text\":\"Both sides have to have zero reserve right?\"}, {\"type\":\"paragraph\",\"text\":\"What he\u2019s saying is ignoring this I can send it and you don\u2019t send it. Presumably we have asymmetric dust limits, is there some weird edge case there?\"}, {\"type\":\"paragraph\",\"text\":\"Only pre any HTLCs right? You could start with a zero balance on one side before any HTLCs have flown?\"}, {\"type\":\"paragraph\",\"text\":\"<https://github.com/lightning/bolts/issues/959>\"}, {\"type\":\"paragraph\",\"text\":\"There was another PR on ours that we were looking at but I guess this clarifies things. If it is a bit we would modify the bit vector to make sure it is only the new anchors or whatever anchors and go from there. Now we can test some stuff out in the wild again, I can take a look at Eugene\u2019s monster PR.\"}, {\"type\":\"heading\",\"text\":\"RBF\"}, {\"type\":\"paragraph\",\"text\":\"One topic that has been discussed a lot recently is RBF. I don\u2019t know if you\u2019ve followed all the discussions on the mailing list about RBF. I am really eager to see people in meatspace and discuss it more.\"}, {\"type\":\"paragraph\",\"text\":\"Why isn\u2019t it as simple as just deleting that other code? If it was me I would just have a pure delete PR.\"}, {\"type\":\"paragraph\",\"text\":\"It is a denial of service attack against Bitcoin Core nodes. The problem is all of this stuff very quickly turns into either a) it is not actually optimal for miners or b) it is a denial of service attack against Bitcoin Core nodes such that you can\u2019t possibly implement it without breaking everything.\"}, {\"type\":\"paragraph\",\"text\":\"Wouldn\u2019t you keep the whole min step thing? Each replacement still needs to replace a certain amount?\"}, {\"type\":\"paragraph\",\"text\":\"One issue is that if the transaction package is going to confirm in the next block, it is actually not optimal for miners to accept a replacement that is smaller but has a higher fee rate. You decrease the value of the next block which is exactly the thing you don\u2019t want to do.\"}, {\"type\":\"paragraph\",\"text\":\"Why would a miner have a bigger mempool and keep the conflicts? You could check only the ancestor package and accept things that have a bigger ancestor package than the things they are replacing, not care about descendants. The miners would keep more and would keep conflicts, for them it would make sense.\"}, {\"type\":\"paragraph\",\"text\":\"You are saying that you look at just the part that is in the next block and then you look at whether or not that has a higher total fee?\"}, {\"type\":\"paragraph\",\"text\":\"No. The code that we would use for RBF on the relaying nodes would not be the exact same code as what the miners would do.\"}, {\"type\":\"paragraph\",\"text\":\"Russell O\u2019Connor\u2019s [proposal](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-February/015717.html) from 2018 is still the best in my opinion.\"}, {\"type\":\"paragraph\",\"text\":\"If a Bitcoin Core node is making decisions that are different from what is being mined you are denial of service attacking yourself. Fundamentally by relaying and by validating and doing all the work you are spending time doing something. If that transaction is something that the creator of that transaction knows will never get mined then they know they can do this all day long.\"}, {\"type\":\"paragraph\",\"text\":\"You are not always doing the optimal thing because there may be descendants. I want to ignore descendants when evaluating whether a package is better than another package. Ignoring descendants, it is much easier because it doesn\u2019t vary from one mempool to another if you only look at ancestors. You still force the ancestor package to increase.\"}, {\"type\":\"paragraph\",\"text\":\"The ancestor package but what about the descendants? You\u2019ve kicked out the descendants and the descendants are a free relay issue. If I can add a bunch of descendants to the mempool and then do something that kicks them out without paying for the descendants then I can do this over and over again and blow up your CPU.\"}, {\"type\":\"paragraph\",\"text\":\"I believe the conflict is fundamental here. The miners don\u2019t care how much spam you\u2019ve got to get through to get to them, that is what their priority is. The network priority is minimize network traffic. These two are in conflict. They are absolutely in conflict. Currently Bitcoin Core biases towards protecting the network rather than optimizing for miners. Not long term incentive compatible.\"}, {\"type\":\"paragraph\",\"text\":\"What you are saying, you don\u2019t care if you are throwing out children. The point is you could also have a world where you just simply don\u2019t accept these children. If you are wasting traffic adding all these children, I guess this gets into the distinction between top block versus not. These descendants being in the top block versus not. Fundamentally if you really wanted to rearchitect the whole mempool from top to bottom what you would really do is say \u201cI am going to aggressively relay things that fit in the next block. Beyond that I am going to aggressively rate limit it. I am going to have a fixed bandwidth buffer for stuff that is not in the next block. If it is in the next block I\u2019ll relay it.\"}, {\"type\":\"paragraph\",\"text\":\"You have less spam problems at that point because anyone trying to spam with tiny replacements is at risk of getting mined at any point. It also gives them emergency override to go \u201cI need to override this so I am going to slam it with a fee that is going to get in the next block and everyone will relay it.\u201d It is also much more miner compatible. Fundamentally the concept of a mempool as being a linear array of transactions that is ready to go into blocks at any point is not optimal for miners. They should be keeping a whole pile of options open and doing this NP complete thing where they are rejuggling things, that is not going to happen.\"}, {\"type\":\"paragraph\",\"text\":\"What is practically optimal for miners is also what they can run in their CPU in a reasonable amount of time and can actually implement. There is an argument to be made that what is optimal for miners is always do whatever Bitcoin Core does because it is probably good enough and anything else takes a lot of effort which may screw you if you make an invalid block.\"}, {\"type\":\"paragraph\",\"text\":\"On your point about evicting descendants being costly. Is it really because it is bounded? You don\u2019t have chains of descendants that can be longer than 25.\"}, {\"type\":\"paragraph\",\"text\":\"It is not bounded because you can do it over and over again.\"}, {\"type\":\"paragraph\",\"text\":\"Every time you are still increasing the package of the ancestors. That on its own will eventually confirm. You will have paid for something.\"}, {\"type\":\"paragraph\",\"text\":\"The question is how much of a blowup compared to current relay cost are you doing? Current relay is very strict. There should be no way to relay anything such that you pay less than 1 satoshi per vbyte of the thing you\u2019re relaying. Full stop, you should always pay at least that. What you\u2019re saying is \u201cYes you can relay more but you\u2019ll pay something\u201d. It is true, you\u2019ll pay for something because you are increasing the fee rate. If you don\u2019t require that you pay an absolute fee for the things you evicted you are potentially paying substantially lower than 1 satoshi per vbyte. The question is how much of a blowup is acceptable, how much of a blowup is it? To make this argument you\u2019d need to go quantify exactly how much blowup can you do, what have you reduced the relay cost to from 1 satoshi per vbyte? I don\u2019t think any of these proposals have done that.\"}, {\"type\":\"paragraph\",\"text\":\"That is something that should be easy to compute. I can try to have a look at it before London. I will discuss this with folks who will be in London.\"}, {\"type\":\"paragraph\",\"text\":\"I will start to review Eugene\u2019s zero conf thing. People can ping on the issue once they have that ready for interop. Then maybe by a meeting or two from now I will have some Taproot PTLC stuff ready and make t-bast\u2019s [gist](https://github.com/t-bast/lightning-docs/blob/master/taproot-updates.md) a little more concrete.\"}, {\"type\":\"paragraph\",\"text\":\"I don\u2019t know if anyone replied to the [gossip thing](https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-February/003470.html) I threw out there. I did promise last meeting I\u2019d put some meat on that proposal. It is still way off.\"}",
    "body": "\nName: Lightning specification call\n\nTopic: Agenda below\n\nLocation: Jitsi\n\nVideo: No video posted online\n\nAgenda: <https://github.com/lightning/bolts/issues/957>\n\n# Organizing a Lightning Core Dev meetup\n\nI was talking about organizing a face to face Lightning Core Dev meetup. If I understand correctly there has only been one formal one and that was in 2019 in Australia. There has been two?\n\nMilan, the kickoff. There has only ever been two.\n\nThat was probably before my time in Bitcoin.\n\nWe get to Bora Bora? Did that come up on the list?\n\nI think it is high time that we meet in person. I know there was one last fall but Rusty couldn\u2019t travel and a bunch of folks couldn\u2019t. Let\u2019s try to get one organized that has as good a participation as possible from the Lightning spec developers. If anyone has questions we can discus right now. I just wanted to give a heads up. I plan to send a survey out just to get some sense for locations and dates that work for folks. It will probably be impossible to accommodate everyone but I\u2019ll do my best to take that information and find a way to get something scheduled in the next few months. I suspect it will be April, May timeframe. I am going to try to make it work, at least by May. Something that works for everyone. Are there any quick questions or things I should be thinking about when trying to organize this? I\u2019ve organized a couple of Core Dev meetups in the past, we\u2019ll take lessons and learnings from that. As they develop we\u2019ll reveal plans and get feedback from everyone to make sure it is as valuable as possible.\n\nThere are a few things popping up randomly that maybe people will be at. I know some people are going to be in London, some people may be in Miami. If we can piggy back maybe that can work but London is in like 3 weeks.\n\nI\u2019m probably the only Lighting one but I\u2019m not going to the UK. I know a number of Core devs aren\u2019t going to the UK either.\n\nSome of our people are going but they are already in Europe, it is a skip. Not a long distance.\n\nI\u2019m happy to go to Europe. Because of the lawsuit currently entering into the UK\u2026 At least until we finish the jurisdiction challenge.\n\nI forgot that was happening in the background.\n\nAs these Bitcoin conferences occur, some subset of us there, let\u2019s meet up and make progress. Work towards to this one where the majority of us can hopefully attend.\n\n# Use warning message in quick close\n\n<https://github.com/lightning/bolts/pull/904>\n\nThis is a one liner to use a warning. This should be easy to integrate. Another thing that we could discuss about that PR is the point Laolu raised. We could add a feature bit for that. I don\u2019t think we need to and I think Matt doesn\u2019t think we need to either.\n\nIf this thing can save you a bunch of chain fees maybe you want to find people that promise to always do it. That was the rationale there. Otherwise you have the fallback thing. Maybe you end up paying more because they are doing weird stuff. I started implementing this, I need to go back to my PR.\n\nWe can separately discuss having a feature bit for the quick close thing itself. But this in general is just adding an extra warning message on the wire. I don\u2019t know why we would add a feature bit for just that.\n\nPeople send warnings today. I get some issues in lnd, an unknown thing. Maybe we should add more logic in there basically. I think c-lightning sends one if you already have a channel that is closing and you try to do a new one. I think Carla has an older PR for that, we just need to revive it so we can see when things are going wrong.\n\nI think we send them too now. It is just a new message type that you are supposed to log.\n\nWe had an older PR that was waiting for stuff to settle down but it is merged now so we could move forward with that. I\u2019m trying to find it now.\n\nI agree it is completely orthogonal to a feature bit so maybe have a quick look at that PR.\n\n# Offers\n\n<https://github.com/lightning/bolts/pull/798>\n\nWe\u2019ve been working a lot on offers on eclair recently. It is making steady progress. I put one comment on the PR about blinded paths in the `payinfo` but apart from that I don\u2019t think there\u2019s much to discuss on our side.\n\nI did the classic pre-meeting \u201cI should do something\u201d. I went through and applied a few changes, a few typos and things. There was a compat break that I have implemented with compat mode. We seem to be pretty close. I look forward to seeing how interop goes once you\u2019ve got that working. There was a request from Matt. We\u2019ve got blinded paths but we don\u2019t have simple route hints. The problem is you can\u2019t pay via a blinded path until we\u2019ve got the pay via blinded path stuff. He was wanting this shim that I\u2019m reluctant to do but it is practical. I can give you a single unblinded hop. We hold our nose and implement for now. Then eventually it will be in the wonderful unicorn, flying car days and we\u2019ll have full blinded payments and we can get rid of it.\n\nTo be clear I am not going to agitate strongly for this. I think it would let us deploy a little quicker. Obviously we would deprecate it within a year. Then we would remove it another year. But if the answer is no I am definitely not going to advocate very strongly for this and push back. I leave it up to you.\n\nI need to dive a bit more into that. I do not realize yet how much work I will have to do. I would be able to know more in a few weeks and then make a recommendation. Right now I suggest to keep it in until we realize that it is too much and we want to ship without it. Then we may want to remove it. I added a comment today which is potentially another breaking thing so you may want to take a look at it. It is about using a single blinded hint for the whole blinded path instead of one per hop. That is something that would change the wire requirements. We need to decide whether we want to do it or not. While I was reviewing Thomas\u2019 PR on eclair to add offers I realized that there this thing which is a routing hint saying how much fees and CLTV delta to use for the parts of the blinded path. Thomas understood it as there must be one for every hop in every blinded path that is in the offer or the invoice. The way I understood it was we only need one per path and we should apply the same fee and CLTV for all hops in the path to hide them more. You don\u2019t want to show there are different fees here. That is an unblinding vector and it takes up less space.\n\nYou still have to indicate the number of hops though.\n\nYeah. You still have to have an unencrypted blob for each of the hops. But for the fees and CLTV you just provide one value that should work for all the hops in that route. It is more lightweight in the offer and in the invoice. Especially if you add dummy hops at the end of the blinded route you don\u2019t have to repeat new fees and CLTV expiry that takes up more space for no reason. It also forces you to have something that is uniform and works for the whole path which makes it hopefully harder to unblind.\n\nDoes that mean you have to go through all the nodes across all the different payment paths, find the one which is charging the highest fees and apply that ubiquitously to every single node?\n\nIn a way that is already what you do. When you include the path you have all the data for all these hops so you just select the highest fee instead of selecting the right fee for each of the hops.\n\nIf you are doing something smart you obfuscate those numbers. It doesn\u2019t help a huge amount because they can still probe. We have a plan for that, that\u2019s later. You put something inside the onion to say \u201cDon\u2019t accept below this fee because they are trying to use it to probe you.\u201d It is not a break for me because I don\u2019t write this field at the moment. We can certainly change it. It is a simplification, it makes sense. You could imagine a case where I am feeding you a blinded path where one is higher. You could argue if it is such an obvious vector then don\u2019t put that in the blinded path, start with the blinded path after that.\n\nOr just use the higher value for everyone. One other thing I was arguing in the route blinding PR is that it may be frightening for the sender to see that there is a high fee to pay for the blinded part of the route. But actually you could reverse that and make it be paid by the merchant. The merchant would discount the value of the real item and would actually pay for the fee of the blinded path himself because it makes sense. The merchant is trying to hide themselves so they should pay the fee for the blinded part of the route.\n\nI buy the argument. If you are paying for liquidity you will end up with this one hop that is potentially significantly higher. But at the moment the Lightning Network is still low. I ACK that, I will write some verbiage around it. Change it to a single that applies across the route, I like it.\n\n# Zero conf channels\n\nPrevious discussion: <https://btctranscripts.com/lightning-specification/2021-11-22-specification-call/#simple-turbo-channels-enablement>\n\nWe have a pretty comprehensive implementation of it but there was that one thing that we left, the channel type or not. Maybe here I can explain our use case or flow versus the reject on accept. For me it is a fail early versus fail after they send you a non-zero value on min depth. In our case, people like Breez are already doing zero conf channels today. If Breez is starting to use Pool to acquire a zero conf channel for onboarding, in our case we have a channel acceptor that looks at the order in Pool and says \u201cThis is not the channel type, we reject.\u201d With this we need a channel acceptor acceptor. Whenever someone sends you an accept message you need to have that hook there. We already have a pre-accept hook versus a post-accept one. Adding the channel type here would let us know if they are actually going to do the thing. Some people commented that they could do whatever anyway but at least we have that first protection. You can say \u201cThey can do that in any case but the protocol is what we expect. The extraneous stuff can be handled on the side.\u201d We have a full implementation. We should probably test some stuff on the side. That\u2019s the one thing. We want a channel type so we can at least say \u201cI want to open a zero conf channel to you\u201d. Whereas right now this is saying \u201cI will allow you to do zero conf after it is extended\u201d. That is a slightly different flow.\n\nDon\u2019t you already have some kind of hooks on the accept channel message? There\u2019s tonnes of fields in the accept channel message that users will presumably want to filter on?\n\nThe way we handle it, depending on how you do it, you either have a function closure that tells you what to post to the other party\u2026 Up until now there has never been a need to do anything on accept channel. Whenever someone sends you an `open_channel` message that\u2019s when you\u2019d say \u201cI only want private channels. I don\u2019t support this feature bit. They have a green alias, I don\u2019t like that.\u201d That is what people use pretty widely today.\n\nYou said on receiving `open_channel`? These are two different directions. You mean before you send `open_channel`?\n\nUs and other implementations have something like a channel acceptor when you receive `open_channel`. You are saying \u201cDo I want to accept this channel since the default things are currently one way?\u201d\n\nLet\u2019s separate the conversation between outbound and inbound channels.\n\nI\u2019m concerned with accepting. Let\u2019s say Breez acquired a channel for their user, a node on the network is now opening a channel to your mobile.\n\nSo it is an outbound channel?\n\nYes it is an outbound channel. The way it is setup, the maker is always the one that is going to be opening the channel, in this case the person who is opening the zero conf channel. Right now in our flow the user would see the `open_channel`, assuming there is a channel type and whatever else, see it is not zero conf and then reject it. Otherwise it would need to accept it and then later on have an exception down the line that they send a `min_depth` of a different value. That\u2019s the flow.\n\nYou flipped it on us again. You are talking about the side that is accepting the channel, not the channel opener. And you want to filter on the `open_channel` message itself.\n\nYes. We do a similar thing. If someone wants anchor only because we have a feature bit or a channel type there, they can say \u201cThat\u2019s not an anchor channel. I\u2019m rejecting it\u201d and everything moves forward like that. I don\u2019t see a reason not to add a channel type here if it can make peering and general protocols built on top of it more explicit. We can fail quicker rather than failing later. The failing later, we would receive the `min_depth`\u2026\n\nYou said this is for the case where a user has received an `open_channel` and then is going to make some decision based on that `open_channel` and then send a response or an `accept_channel`. But once you\u2019ve received that `open_channel` you now have all the information. The `min_depth` is only in the `accept_channel`. Presumably the node that is opening the channel, if you tell it it is zero conf it is just going to accept that because why wouldn\u2019t it? In my understanding of the way we\u2019ve done it and c-lightning has spoken about implementing it just seeing the `open_channel` and knowing what you are going to write in the `accept_channel` is sufficient to know whether the channel will be zero conf.\n\nThat\u2019s the difference. Y\u2019all are saying zero conf all day everyday. We are saying zero conf under these very precise scenarios. It wouldn\u2019t be a default thing for the world. I don\u2019t see any downside and I feel like it makes certain protocols more precise because you can fail earlier. We have a lot of feature bits, we already have a channel type here too. Maybe certain channels can\u2019t support zero conf in the future.\n\nAnd multi funder is a whole other discussion.\n\nWe have the ability at the protocol level to allow that filtering to exist in the future by having the zero conf bit here.\n\nIn the case of you\u2019ve received an `open_channel` message, you say \u201cI\u2019m going to do zero conf with this channel\u201d. Presumably at that point you\u2019ve done further out of band negotiation. Obviously you are not going to accept zero conf from anyone, you are going to say \u201cThis node, we\u2019ve already negotiated this and that\u201d. Why can that negotiation not be the thing that decides this instead of having it be a negotiation? First you negotiate, you know you are going to do zero conf with this node, you get a channel from that node and then you do an additional negotiation step and say \u201cIt must be zero conf\u201d.\n\nThis is when things are extended. At that point maybe they are eligible. But in this case whenever you send it I know it is there at runtime. We always try to verify the lowest layer. Let\u2019s say we are doing this thing and it is not in the feature bit. Then the user sends `min_depth` zero, for whatever reason other party says \u201cNo\u201d. At that point you have a weird silent failure. Now the receiver is saying \u201cZero conf\u201d rather than the proposer. If the proposer initially gets the `accept_channel` and then does nothing, UX wise it is hard to have a consistent flow there.\n\nI don\u2019t understand why. You\u2019ve already negotiated it. The initiator and the acceptor has negotiated it. The acceptor says \u201cYes zero conf\u201d and now the initiator is like \u201cActually no, not zero conf\u201d. Then you\u2019re saying \u201cThe UX is going to be confused.\u201d Of course the UX is confused, the initiator is buggy.\n\nIf we have a flow here where we know the initiator is doing a weird thing from the beginning we are able to make things a lot more consistent. The way it works, we ignore them, we do matching again and we can proceed. While with this one it is a weird indeterminate thing.\n\nThe channel now has to wait for a few confirmations. So what?\n\nBut now the user\u2019s expectation is trashed. \u201cI thought I was getting a zero conf channel. I can\u2019t use it at all. Is the wallet broken?\u201d\n\nIt is the user\u2019s fault.\n\nIt is not the user\u2019s fault. It is the protocol not being able to surface and allow things to be explicit like this. Can you explain the cost of adding a channel type feature bit here? In the future maybe certain channel types aren\u2019t zero conf friendly at all. We are able to add a provision for that from the get go versus in the future realizing that the `min_depth` dance isn\u2019t sufficient for whatever new super Taproot covenant channel type people come up with.\n\nI am just trying to understand exactly the differences here in terms of the flow.\n\nThe UX is inconsistent because after everything is under way things can break down. Versus just saying \u201cWe\u2019ve checked at the beginning. You have the `open_channel` rejected there.\u201d Then we can at least say \u201cWe weren\u2019t able to find a match for you\u201d versus \u201cWe\u2019ve found a match but then it turned out to be a counterfeit good basically\u201d. It is like buying a car, they told you it was manual and it is automatic. You are like \u201cWhat is this? I can\u2019t drive this thing.\u201d That\u2019s a framing. It is making sure the user is buying or selling the good as much as we can validate it upfront.\n\nThe problem with this PR is it conflicts two things. One is if you do zero conf you need some alias mechanism, you need a name for it before it is confirmed. That\u2019s almost useful. We\u2019ve decided we like that. Whether you are doing zero conf or not it is nice to have this alias facility, private channels and stuff like that. That\u2019s almost a PR by itself. The problem with zero conf is if you say \u201cYes I want a zero conf channel\u201d are you committing to trusting them with the channel? I can open a zero conf channel and let you open it and pretend and then never forward anything until it is confirmed. But presumably when you\u2019ve said \u201cI want a zero conf channel\u201d you are all in and ready to trust with this. Or you are on the side that doesn\u2019t require trust. That is what you are trying to signal.\n\nOne other slight thing here with the way Pool works, we like this because it increases the set of signers required to double spend. For example if I have a batch of 5 people opening a channel it requires all 5 of them to double spend rather than just the person that was opening. It also requires us to double spend as well too. It increases the total set of collusion that is necessary in order to double spend the output. The reason they can\u2019t double spend is they are in a UTXO that is a 2-of-2 with us. They would need us and every other person as well to double spend the entire batch. That\u2019s the one difference security model wise with how this works in this setting. It is like a coinjoin where everyone has a timelocked input basically. The input will only be signed if things look good. The trust stuff is explicit. That\u2019s another reason to add a channel type there. \u201cDo I want to accept this zero conf thing?\u201d You are right that there is a double opt-in. We are just trying to make it more explicit. It is more sensible if we know zero conf stuff can\u2019t work for every channel type.\n\nOriginally the channel types were just to get around this hack. There were some features we had to remember. If you negotiated that at the beginning that made sense for the whole channel lifetime independent of what\u2019s in the future. But generalizing it to \u201cThis is not persistent state but this is stuff about this channel\u201d. It is not objectionable.\n\nIf we want explicit signaling I would strongly suggest we switch to a TLV in `open_channel` rather than making it a channel type.\n\nThat\u2019s exactly what we have. We have a TLV that is a channel type in `open_channel`.\n\nInternally from the architecture, when we switched across I just went through and changed everything to channel types internally. It was so much nicer. Instead of all these adhoc things going \u201cIs this an anchor channel? Is this a static remote key channel?\u201d suddenly became this bit test of the channel type, this field that went all the way through.\n\nFor us it allows us to move our implementation closer to the protocol. We already had the channel type before but now it is one-to-one. It is a different enum or whatever but same thing.\n\nIn retrospect we should have done this originally. There are two things. One is do you get an alias? I think the answer is everyone wants an alias. You need an alias if you are doing the zero conf thing obviously. But the way the spec was written is that you\u2019ll get one. I think this is nice. I am actually not all that happy with a channel type the more I think about it. But I do want to go and implement it and see what that does.\n\nIt does feel weird because channel type is all stuff that is only persistent.\n\nIt is today but maybe that is inflexible thinking. My only caveat on this, it is not necessarily a huge issue, you open a channel and you go \u201cI expected that to be zero conf\u201d. You can specify that afterwards. We were going to have an API where you could go \u201cTrust this node ID\u201d. Obviously if you open a new channel it would be zero conf but you could also zero conf an existing channel by going \u201cI\u2019m going to start ACKing it\u201d. Assuming that it had support for the alias so you were ready to do that. You would end up with a zero conf but you would never have signaled a zero conf. I guess you are free to do that.\n\nPresumably the way y\u2019all would implement that is that even if your counterparty says \u201c6 confs\u201d you will always send the `funding_locked` immediately after you broadcast the funding transaction if you are the initiator. Is that what you are thinking?\n\nYeah. If you are the initiator and there is no `push_msat`. And in our case with dual open, if you\u2019ve got no funds on the line we will just go \u201cSure whatever\u201d, we will zero conf stuff.\n\nWhy does `push_msat` matter?\n\nIf I have all the funds in the channel then I can use the channel immediately. If you screw me you\u2019ve just lost money. But if I\u2019ve `push_msat` to you you can push stuff through the channel.\n\nYou are still presumably not going to double spend yourself. It just prevents you from double spending the funding transaction? The idea is that you\u2019d like to be able to continue double spending the funding transaction? The initiator pushes msat to the other counterparty, it is all your funds but you\u2019ve given it to the initiate key?\n\nSpecifying `push_msat` puts you at some risk of them getting the money. If it is single conf even if your double spend fails you still have everything.\n\nPresumably you were ok with them getting the money because you\u2019ve pushed msat to them?\n\nIf you wanted to scam them maybe you wouldn\u2019t do that.\n\nThe guy who accepts the `push_msat`, if it is a payment for something that has been semi trusted and done before, \u201cI will push you msat because I opened this channel because you opened a channel to me. I opened a channel back in response. I will push you money through that.\u201d But if you accept it as zero conf and they double spend it you lost that msat, maybe you opened a channel in response. It is more the guy who accepts the `push_msat` that has a risk of accepting zero conf.\n\nYou can generalize this for the dual funding case.\n\nThis is an interesting question then. Basically the channel type or TLV or whatever would say \u201cEither send me an accept with zero `min_depth` or I\u2019m going to immediately close the channel.\u201d\n\nOr send a warning message or error and whatever else.\n\nThe initiator will still always send a `funding _locked` immediately and the receiver can still send a `funding_locked` immediately if they want to. The feature bit is only an indicator of either you do this or I am going to close the channel.\n\nIt should also indicate that you have some degree of trust, that you will route. I could send whatever I want across the wire and not consider the channel open until\u2026 I think it should imply that you are going to let them do zero conf.\n\nThey can just deny any channel that has this set. Maybe that helps, maybe that doesn\u2019t. They at least have that ability.\n\nThe thing is it should flag that they are trusting the zero conf, not just that they are walking through the protocol.\n\nIt should say that they must, not just that they can. If you see this bit and you are going to send an `accept_channel` that does not have a zero conf `min_depth` you must fail the channel.\n\nNegotiation has failed at that point.\n\nIt is not optional.\n\nOn the alias being decoupled, do we like that in the same combo still? The alias thing has a feature bit already right?\n\nYes.\n\nYou must only route through this bit, not there is an alias offered. The feature bit is not just for the alias itself.\n\nThe feature bit is weird. It is like \u201cOnly use this one. I really understand what I\u2019m doing and I only want you to use this. Discard the real short channel ID.\u201d This is kind of what you want. But whether we should use a different feature bit for that, I am going to have to look back. We do want a way to say \u201cI am all in on this whole alias idea.\u201d\n\nIt should be all or nothing.\n\nBut for backwards compat or \u201cI don\u2019t care. It is going to be a public channel but it is zero conf for now\u201d I can use an alias and then throw it away. This is where the alias becomes a bit schizophrenic. We\u2019ve got these two roles. The feature bit would say \u201cWe\u2019re all alias and we are only alias\u201d. It is kind of overloaded. Maybe we should go back and change the bit number. If I switch it to a channel type I\u2019ll see what happens.\n\nI thought you did switch it to a channel type.\n\nThat is a channel type. Because that is something you have got to remember forever. The same bit would be used for the other channel type so now I have to find another one.\n\nI think it is an example of the advantage of the feature bit. You can have these as individual things. Zero conf and the alias only or you can have all of them. That\u2019s nice in terms of the bit vector comparison thing.\n\nThis is where I\u2019m coming around to they are separate things.\n\nA different feature bit.\n\nYes. Part of the roadblock that we got is because we put them both in together. It became this logjam.\n\nZero conf requires aliasing though yes?\n\nIn order to receive before confirmed yes but maybe we don\u2019t care about that eventually.\n\nYes. If you don\u2019t have an alias then all that can happen is they can push sats through you but you can\u2019t use the channel.\n\nIt is kind of useless without that. Does that mean that you intend to split this PR into two? Or are we going to continue? It sounds like LND already has an implementation, LDK has one.\n\nWe have one of everything. The only divergence is the upfront feature bit check. I am cool with keeping it as is and we maybe throw out the bits. Once we have that squared up we can look at cross compat testing.\n\nAdd a TLV rather than defining a new bit.\n\nWe have a TLV.\n\nAdd a TLV that says the required bit.\n\nI\u2019ll edit this PR for now. If I was smarter I\u2019d have split it into two. I don\u2019t think it is worth splitting now.\n\nIt is pretty small, not a multi file mega thing.\n\nAction Rusty to do another pass, make a channel type and see what happens, how bad it gets.\n\n# Zero reserve\n\nI\u2019m going to jot that down on the PR. One other thing related to this is zero reserve. Eugene is implementing this and asking questions about zero reserve. Right now I let you cheat me for free but maybe it is not useful unless we have it both ways. I think he was wondering do you always do zero reserve? I think right now technically if you send zero it is in violation of the spec. I think we have must be greater than zero thing.\n\nWe accept it, we do not allow you to send it currently. We may at some point allow you to send it. We accept it, maybe in violation of the spec.\n\nMust set greater than or equal to `dust_limit_satoshis`.\n\nIf you set that to zero there is that weird interaction. I looked at a really old Breez PR, I found that it allowed zero reserve but it didn\u2019t because it would reject it if it was less than the dust limit. We also had some dust limit revelations a few months ago as far as interactions with other fields.\n\nAt least in our codebase I don\u2019t think there\u2019s a weird interaction. If the output value is less than the dust limit you still have to remove it.\n\nOtherwise you\u2019d have a weird situation where I make the reserve on your commitment transaction below dust which means it can\u2019t propagate. Maybe I can do that by rebalancing or something like that.\n\nThere is still a `dust_limit_satoshis`.\n\nThe issue is you can end up with a zero output transaction.\n\nAs long as your dust limit is non-zero. You still remove the output.\n\nNo you remove all the outputs, that\u2019s the problem. That\u2019s not a valid transaction.\n\nA zero output transaction, I see your point.\n\nBy forcing a reserve you are saying that someone has an output at all times. I think that was the corner case that we ended up slamming into. Maybe it doesn\u2019t matter. What are you doing with your life if you\u2019ve managed to turn everything into dust? I don\u2019t if that is real but I remember that corner case.\n\nI know Breez is running a LND fork and they already doing this in the wild.\n\nIf the other guy lets you have zero reserve on your side it is all a win for you. It is only for the other guy that it is a risk.\n\nExactly. If you say I can have zero I\u2019m fine with that. That doesn\u2019t necessarily give you what you want. You want to be able to do \u201csend all\u201d, close the app and walk away. But right now people have that weird change value lingering. I\u2019m not sure how the mobile apps handle it in practice.\n\nThat\u2019s why we did zero reserve on Phoenix, to be able to do \u201csend all\u201d and to have users send all of their balance out, there is nothing remaining.\n\nBecause otherwise it is weird. You have this value you can\u2019t move and people will get frustrated about that.\n\nWe had users who were like \u201cNo I need this or I can\u2019t ship\u201d. I think we have separate dust enforcement around our outputs. That\u2019s a good point, there may be a corner case where you could hit a zero output transaction.\n\nThat was the killer. It is unspendable. In one way you don\u2019t care, on the other hand it is UTXO damage.\n\nIt is application level brain damage at that point.\n\nSo this is one of those more investigation required things?\n\nWrite in the spec what you do if you end up in this case. Or figure out a way to avoid it. Say that \u201cThe minimum channel size must be such that you can\u2019t be all dust\u201d. Though that isn\u2019t actually possible because your HTLC dust limit depends on your fee rate and stuff like that.\n\nIf it is only when anchor outputs, zero fee is used then you have no risk. There is no trim to dust, it is only the dust limit on HTLCs. If your channel is not really small you will always have outputs in there.\n\nWhat do you mean there is no dust? What if we just move the reserve to the anchor output? Maybe that would solve it.\n\nHe\u2019s two steps ahead. I was suggesting that you make your channel size such that you can never have it all dust. But that is not possible in a classic channel because your HTLC size that gets trimmed depends on your fee rate. But as he\u2019s saying, that is not true with zero fee HTLC anchors. Modern anchors, that is not true anymore. You could just figure out what the number is and don\u2019t have a channel smaller than this and you can have zero reserve. Maybe that\u2019s the answer.\n\nCan you explain the making sure you never have dust? You mean you have a minimum channel size that is just above dust?\n\nTo avoid this problem where you end up with zero outputs because everything is dust, if you blow away the reserve requirement, you could fill it with enough HTLCs that are all dust. Suddenly you have got zero outputs. You want to avoid that. Figure out what the numbers are. It depends on the max number of HTLCs and your dust limit. But it no longer depends on the fee rate which was the impossible one. If you put that as a requirement, you\u2019ve got to have modern anchor and you\u2019ve got to have larger than this number, formula whatever, then you can have zero reserve. I think that covers the corner case.\n\nYou could probably also get away with that Antoine PR that is overly specific. Presumably at this point every implementation has their own separate dust limiting functionality and you could also lean on that depending on how you implemented that. Maybe that is too weird.\n\nIt seems like anchors makes it possible for you to compute what this minimum channel size should be to make sure nothing is ever fully dust. You always have enough funds left over after paying for the fees of HTLCs, the first level output that is.\n\nIndependent of fee rate which is nice.\n\nThere is still one edge case. If the fee rate goes really, really high and you are not capping it because of anchor. If you don\u2019t have any HTLCs and the fee rate goes to the roof\u2026 there is only one guy paying the fee\u2026\n\nAs long as that guy paying the fee is the one with all the balance and the other one has rounds to dust.\n\nIt is possible in theory, yeah.\n\nYou may have to put a clause in the fee rate saying you don\u2019t do that. \u201cDon\u2019t set a fee rate such that you would end up with zero outputs\u201d. Figure out exactly what to test rather than just saying that. Assuming we can work out why are we suggesting this is a new channel type? A zero reserve channel type?\n\nI don\u2019t see why it would be.\n\nThe argument is \u201cThis is the kind of channel I want\u201d.\n\nIt would be the exact same reasoning of the previous discussion. They can always send it and presumably you negotiated it in advance.\n\nSimilar thing. This would give them the level of guarantee they have today. But more broadly in the network. By them I mean people like Muun and Breez that already do it.\n\nIt is one of those things that are pre-negotiated.\n\nThat does touch on what Lisa is doing on dual funding. On dual funding she says that the reserve is not negotiated, it is only a percentage. There is a boolean saying \u201cInclude it or not include it\u201d. You decide it at what step exactly? In which message? I don\u2019t remember.\n\nI don\u2019t think I have added the boolean thing yet. We\u2019ve talked about adding it.\n\nAt the moment it is 1 percent. The 1 percent is known at negotiation time, you choose the protocol you are using. I haven\u2019t added the boolean thing yet.\n\n Even if we had the boolean it would be after discussing the channel types. So maybe it would be the same thing as for zero conf. If we want to know it upfront then we do need a channel type.\n\nI think it makes sense as a channel type. It also is a feature bit. You know what you are getting. The reason I like 1 percent reserve is the same kind of reason. I could tell you exactly what channel size you will have after putting in this many sats. If we make it a channel type it falls automatically into dual funding anyway.\n\nDoes anybody know if you can get zero outputs with just one side sending zero channel reserve? Because there\u2019s an asymmetry here?\n\nBoth sides have to have zero reserve right?\n\nWhat he\u2019s saying is ignoring this I can send it and you don\u2019t send it. Presumably we have asymmetric dust limits, is there some weird edge case there?\n\nOnly pre any HTLCs right? You could start with a zero balance on one side before any HTLCs have flown?\n\n<https://github.com/lightning/bolts/issues/959>\n\nThere was another PR on ours that we were looking at but I guess this clarifies things. If it is a bit we would modify the bit vector to make sure it is only the new anchors or whatever anchors and go from there. Now we can test some stuff out in the wild again, I can take a look at Eugene\u2019s monster PR.\n\n# RBF\n\nOne topic that has been discussed a lot recently is RBF. I don\u2019t know if you\u2019ve followed all the discussions on the mailing list about RBF. I am really eager to see people in meatspace and discuss it more.\n\nWhy isn\u2019t it as simple as just deleting that other code? If it was me I would just have a pure delete PR.\n\nIt is a denial of service attack against Bitcoin Core nodes. The problem is all of this stuff very quickly turns into either a) it is not actually optimal for miners or b) it is a denial of service attack against Bitcoin Core nodes such that you can\u2019t possibly implement it without breaking everything.\n\nWouldn\u2019t you keep the whole min step thing? Each replacement still needs to replace a certain amount?\n\nOne issue is that if the transaction package is going to confirm in the next block, it is actually not optimal for miners to accept a replacement that is smaller but has a higher fee rate. You decrease the value of the next block which is exactly the thing you don\u2019t want to do.\n\nWhy would a miner have a bigger mempool and keep the conflicts? You could check only the ancestor package and accept things that have a bigger ancestor package than the things they are replacing, not care about descendants. The miners would keep more and would keep conflicts, for them it would make sense.\n\nYou are saying that you look at just the part that is in the next block and then you look at whether or not that has a higher total fee?\n\nNo. The code that we would use for RBF on the relaying nodes would not be the exact same code as what the miners would do.\n\nRussell O\u2019Connor\u2019s [proposal](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-February/015717.html) from 2018 is still the best in my opinion.\n\nIf a Bitcoin Core node is making decisions that are different from what is being mined you are denial of service attacking yourself. Fundamentally by relaying and by validating and doing all the work you are spending time doing something. If that transaction is something that the creator of that transaction knows will never get mined then they know they can do this all day long.\n\nYou are not always doing the optimal thing because there may be descendants. I want to ignore descendants when evaluating whether a package is better than another package. Ignoring descendants, it is much easier because it doesn\u2019t vary from one mempool to another if you only look at ancestors. You still force the ancestor package to increase.\n\nThe ancestor package but what about the descendants? You\u2019ve kicked out the descendants and the descendants are a free relay issue. If I can add a bunch of descendants to the mempool and then do something that kicks them out without paying for the descendants then I can do this over and over again and blow up your CPU.\n\nI believe the conflict is fundamental here. The miners don\u2019t care how much spam you\u2019ve got to get through to get to them, that is what their priority is. The network priority is minimize network traffic. These two are in conflict. They are absolutely in conflict. Currently Bitcoin Core biases towards protecting the network rather than optimizing for miners. Not long term incentive compatible.\n\nWhat you are saying, you don\u2019t care if you are throwing out children. The point is you could also have a world where you just simply don\u2019t accept these children. If you are wasting traffic adding all these children, I guess this gets into the distinction between top block versus not. These descendants being in the top block versus not. Fundamentally if you really wanted to rearchitect the whole mempool from top to bottom what you would really do is say \u201cI am going to aggressively relay things that fit in the next block. Beyond that I am going to aggressively rate limit it. I am going to have a fixed bandwidth buffer for stuff that is not in the next block. If it is in the next block I\u2019ll relay it.\n\nYou have less spam problems at that point because anyone trying to spam with tiny replacements is at risk of getting mined at any point. It also gives them emergency override to go \u201cI need to override this so I am going to slam it with a fee that is going to get in the next block and everyone will relay it.\u201d It is also much more miner compatible. Fundamentally the concept of a mempool as being a linear array of transactions that is ready to go into blocks at any point is not optimal for miners. They should be keeping a whole pile of options open and doing this NP complete thing where they are rejuggling things, that is not going to happen.\n\nWhat is practically optimal for miners is also what they can run in their CPU in a reasonable amount of time and can actually implement. There is an argument to be made that what is optimal for miners is always do whatever Bitcoin Core does because it is probably good enough and anything else takes a lot of effort which may screw you if you make an invalid block.\n\nOn your point about evicting descendants being costly. Is it really because it is bounded? You don\u2019t have chains of descendants that can be longer than 25.\n\nIt is not bounded because you can do it over and over again.\n\nEvery time you are still increasing the package of the ancestors. That on its own will eventually confirm. You will have paid for something.\n\nThe question is how much of a blowup compared to current relay cost are you doing? Current relay is very strict. There should be no way to relay anything such that you pay less than 1 satoshi per vbyte of the thing you\u2019re relaying. Full stop, you should always pay at least that. What you\u2019re saying is \u201cYes you can relay more but you\u2019ll pay something\u201d. It is true, you\u2019ll pay for something because you are increasing the fee rate. If you don\u2019t require that you pay an absolute fee for the things you evicted you are potentially paying substantially lower than 1 satoshi per vbyte. The question is how much of a blowup is acceptable, how much of a blowup is it? To make this argument you\u2019d need to go quantify exactly how much blowup can you do, what have you reduced the relay cost to from 1 satoshi per vbyte? I don\u2019t think any of these proposals have done that.\n\nThat is something that should be easy to compute. I can try to have a look at it before London. I will discuss this with folks who will be in London.\n\nI will start to review Eugene\u2019s zero conf thing. People can ping on the issue once they have that ready for interop. Then maybe by a meeting or two from now I will have some Taproot PTLC stuff ready and make t-bast\u2019s [gist](https://github.com/t-bast/lightning-docs/blob/master/taproot-updates.md) a little more concrete.\n\nI don\u2019t know if anyone replied to the [gossip thing](https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-February/003470.html) I threw out there. I did promise last meeting I\u2019d put some meat on that proposal. It is still way off.\n\n\n",
    "body_type": "markdown",
    "created_at": "2022-02-14T00:00:00.000Z",
    "domain": "https://btctranscripts.com/",
    "url": "https://btctranscripts.com/lightning-specification/2022-02-14-specification-call",
    "categories": [
        "meetup"
    ],
    "tags": [
        "lightning"
    ],
    "indexed_at": "2024-03-21T16:33:36.671Z",
    "transcript_by": "Michael Folkson",
    "summary": "In a recent convergence of minds within the Bitcoin development community, discussions on the Lightning Network's future took center stage, revealing the intricate balance between innovation and practicality. The dialogue, stemming from the latest Lightning specification call, provided valuable insights into current technical enhancements, collaborative efforts, and the ever-evolving landscape of cryptocurrency protocols.\n\nThe discussion commenced with an ambitious plan to organize a face-to-face Lightning Core Dev meetup, reminiscent of previous successful gatherings in Milan and Australia. This initiative, driven by a desire to strengthen collaboration among developers, faces logistical challenges due to diverse locations and schedules. However, there's a palpable commitment to overcoming these hurdles, with considerations for leveraging existing Bitcoin conferences as platforms for impromptu meetups alongside planning a more formal assembly in the near future.\n\nA significant portion of the conversation pivoted towards technical refinements within the Lightning Network, specifically the proposal to integrate warning messages during swift channel closures. This proactive measure aims to safeguard users from potential fund losses attributable to chain fees, reflecting a collective effort to refine user experience through lessons learned from past developments. The consensus leaned towards a streamlined implementation, eschewing additional complexities to maintain the system's intuitiveness and effectiveness.\n\nFurther discourse delved into the ongoing enhancements on 'offers'\u2014a mechanism poised to simplify transactions over the Lightning Network. Developers are diligently working on refining these proposals, ironing out minor errors, and contemplating compatibility breaks with a keen eye on future interoperability. The inclusion of route hints in payment information sparked debate, highlighting the delicate act of balancing user simplicity with privacy and efficiency, indicative of the broader challenge of enhancing the Lightning Network's functionality without compromising its core values.\n\nThe intricacies of implementing zero-confirmation ('zero conf') channels were also explored, emphasizing the nuanced approach required to align such features with the network's security and usability standards. The conversation underscored the importance of clear communication and consensus on protocols, illustrating the community's dedication to advancing the Lightning Network's capabilities cautiously.\n\nMoreover, the introduction of zero conf channels was dissected, showcasing divergent approaches and their underlying technical complexities. A key contention revolved around handling these channels across different implementations, stressing the need for fail-safe mechanisms and explicit signaling to streamline operations and minimize misunderstandings. The notion of future-proofing the protocol emerged, advocating for inherent support of granular filtering mechanisms to accommodate the evolving ecosystem.\n\nThe dialogue further ventured into the realm of aliasing and zero reserve channels, shedding light on the technical hurdles and strategic decisions shaping the network's trajectory. Discussions ranged from the feasibility of introducing new feature bits for alias usage to the innovative yet challenging concept of zero reserve channels. These deliberations highlighted the developers' endeavor to balance technical specifications with the network's innovative potential, alongside ensuring cross-compatibility and optimal user experience.\n\nLastly, the broader implications of transaction relay and mining process optimizations were examined, reflecting on Russell O\u2019Connor's 2018 proposal to address the conflict between network efficiency and miner incentives. This segment revealed the complexities of aligning the priorities of miners with the overall health of the network, proposing adjustments to Replace-By-Fee (RBF) protocols and mempool management strategies to enhance throughput and reduce spam.\n\nThrough these multifaceted discussions, the Bitcoin development community continues to navigate the complex landscape of technological innovation, striving to bolster the Lightning Network's robustness, efficiency, and accessibility. The dedication to fostering a scalable, efficient, and user-friendly layer atop the Bitcoin blockchain remains evident, even as developers tackle the nuanced challenges inherent in pioneering such groundbreaking endeavors."
}