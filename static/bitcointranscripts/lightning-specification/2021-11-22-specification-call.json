{
    "id": "bitcointranscripts+lightning-specification+2021-11-22-specification-call",
    "title": "Lightning Specification Meeting - Agenda 0936",
    "body_formatted": "{\"type\":\"paragraph\",\"text\":\"Name: Lightning specification call\"}, {\"type\":\"paragraph\",\"text\":\"Topic: Agenda below\"}, {\"type\":\"paragraph\",\"text\":\"Location: Google Meet\"}, {\"type\":\"paragraph\",\"text\":\"Video: No video posted online\"}, {\"type\":\"paragraph\",\"text\":\"Agenda: <https://github.com/lightning/bolts/issues/936>\"}, {\"type\":\"paragraph\",\"text\":\"The conversation has been anonymized by default to protect the identities of the participants. Those who have given permission for their comments to be attributed are attributed. If you were a participant and would like your comments to be attributed please get in touch.\"}, {\"type\":\"heading\",\"text\":\"BOLT 7 onion message support\"}, {\"type\":\"paragraph\",\"text\":\"<https://github.com/lightning/bolts/pull/759>\"}, {\"type\":\"paragraph\",\"text\":\"So PR 759 is built on PR 765 because we used the route blinding to decrypt where the end is going to go. After feedback from Matt I think we have a pretty good, close to final on onion message support. The original onion message was basically exactly the same as we do for HTLCs. The only difference is that it could be variable size. You unwrap the onion, figure where it is going next and send it onwards. The endpoint would have some extra fields to contain the data. That\u2019s still the case but now it is always a blinded onion. When you unwrap it you get this second layer of encryption and then you decrypt that. The reason for that is that we were using that for onion replies. I send you an onion message and I include this route blinding path that you can drop into the onion to get the reply back to me. But that made it asymmetric and you could tell the difference between someone sending you the onion message and sending the onion reply. We went \u201cNo that\u2019s it. It is always blinded even when that is gratuitous.\u201d There is no particular reason to blind a message if you know exactly where it is going. But it does make them uniform. Basically route blinding is now compulsory in an onion message. But it is pretty straightforward. It is exactly the same onion format we use in HTLCs, you pull it apart. I have test vectors, Thomas H of ACINQ has been working his way through them. He found some bugs in my test vectors that basically work but I\u2019ve had some cut and paste errors that I have to get back to. He has got interoperability between c-lightning and eclair on a slightly previous revision of onion messages. We tweaked the spec in a couple of small ways for the final version. The message number is now 513, it was previously in the gossip range and everyone objected to that, it was obviously not a gossip message. Now it is 513 which is undefined range. You can ignore it because it is odd. There were a couple of fields that were unified when t-bast did the route blinding stuff that will be the same as the ones we want to use in route blinded HTLCs. There were some minor field renumberings that don\u2019t affect anyone except c-lightning, c-lightning now has to do both. I\u2019ve implemented that and I think we are very close to finalizing on the two implementations there. I\u2019m hoping that will happen this week. I would really like Matt to get back and reproduce that so we\u2019ve got a three way compatibility test for at least that part. That is all looking really good. Hopefully that won\u2019t change again. Obviously that leads us into offers which is the next bikeshedding thing on top of onion messages. I am hoping once we\u2019ve formal interoperability of the slightly tweaked spec we can have our two implementation bake off test and all the test vectors complete. Definitely by next meeting we should have both implementations 100 percent I hope.\"}, {\"type\":\"paragraph\",\"text\":\"I am pretty sure we will have by the next meeting complete interoperability between eclair and c-lightning. If people have time to review the PRs and find things that look odd. Maybe on the route blinding one, by specifying the route blinding for payments, it was mostly useful for onion messages as well. Right now there is the real spec part that updates the BOLT and only adds the things that are necessary to the onion message and the low level utilities for route blinding. I also have a separate [document](https://github.com/lightning/bolts/pull/765) that is a proposal format with more details and documents and more brainstorming kind of things around payments. I am not sure that should be merged initially so let me know if there are parts to remove in the first version that we will add when we actually use route blinding for payments. That may make sense.\"}, {\"type\":\"paragraph\",\"text\":\"c-lightning has support in experimental mode for an earlier version of the route blinding for payments too. It is pretty trivial. It needs to be updated for the modern spec. It is really easy. The only thing that we do not support in onion messages is route blinding direction by short channel ID because I simply haven\u2019t implemented it yet, there is a FIXME. You can either specify the next hop by short channel ID or by full node ID. I do not yet support short channel ID but I will fix that before the next release. I originally ripped it out but t-bast put it back because it makes more sense for payments anyway. It is nicer, it is more compact, you use less space in the onion. For payments where the onion is a fixed size that is perhaps more critical.\"}, {\"type\":\"paragraph\",\"text\":\"It sounds like both route blinding and onion messages, we might have some level of interoperability between c-lightning and eclair by the next meeting?\"}, {\"type\":\"paragraph\",\"text\":\"Yeah we had it then we tweaked it. We both broke it in the same way.\"}, {\"type\":\"paragraph\",\"text\":\"It is Thanksgiving week here in the US so you\u2019re probably not going to get a lot of work out of the rest of us.\"}, {\"type\":\"paragraph\",\"text\":\"One more question about the onion messages. We\u2019ve had a discussion on Twitter and so on and I am still surprised that none of you seem to be very concerned about abuse of these onion messages. You can route them in 27 hops all across the network, it seems like we are stepping over that as easy as we did with the HTLCs and replicate the same problem in onion messages. I know they are lightweight etc but isn\u2019t there the endgame here that no one wants to forward onion messages and you can only connect directly. You have no privacy gain because of that. You might as well have not done onion messages.\"}, {\"type\":\"paragraph\",\"text\":\"I am concerned as well.\"}, {\"type\":\"paragraph\",\"text\":\"There are a few things we can do with onion messages that we can\u2019t do necessarily with HTLCs. Maybe we can approximate the failure modes of HTLCs. One obvious thing that I think Rusty has mentioned before is the ability to tell a peer \u201cYou are sending me too many onion messages. Shut up or slow down.\u201d That peer doesn\u2019t just blindly drop onion messages based on a flow rate to that next peer who told them to slow down but actually can do it based on the previous hop. That peer who gets told \u201cSlow down\u201d, they can look at their inbound onion message flows and say \u201cThe source of all these onion messages is that peer. I am going to rate limit him and I am going to tell him to slow down.\u201d You can do a backwards flowing rate limiting or flow control there. A little bit naive flow control but does let you rate limit someone and then tell them to do it based on source. If you are rate limiting based on source and it flows backwards\u2026\"}, {\"type\":\"paragraph\",\"text\":\"The trick is you do it without state. What happens if you are being flooded then next time you go into the thing that you have to rate limit, you tell the source to rate limit it. You are going to hit the path that is flooding you most. If someone is flooding down one path that will get it. If someone floods the entire network, sure.\"}, {\"type\":\"paragraph\",\"text\":\"The answer to flooding the whole network is you stop accepting onion messages for forwarding except from someone you have a channel with. Now you can\u2019t necessarily flood everything.\"}, {\"type\":\"paragraph\",\"text\":\"Would that really address things though? It seems like rate limiting is a requirement and the existence of that destroys quality of service. You don\u2019t really have any guarantees. It is even more unreliable as a messaging thing. Maybe that is ok for certain things.\"}, {\"type\":\"paragraph\",\"text\":\"Yes, the internet works by doing retransmissions.\"}, {\"type\":\"paragraph\",\"text\":\"The Tor network.\"}, {\"type\":\"paragraph\",\"text\":\"Tor has centralized rate limiting. We can do that too but then we\u2019re biting off a pretty big challenge there.\"}, {\"type\":\"paragraph\",\"text\":\"Tor does not have centralized rate limiting.\"}, {\"type\":\"paragraph\",\"text\":\"What do you mean? The directory authorities.\"}, {\"type\":\"paragraph\",\"text\":\"Tor has centralized selection of pseudo honest nodes but anyone can connect and start flooding the Tor network. They don\u2019t have centralized rate limiting.\"}, {\"type\":\"paragraph\",\"text\":\"<https://blog.torproject.org/research-problem-adaptive-throttling-tor-clients-entry-guards/>\"}, {\"type\":\"paragraph\",\"text\":\"It is closed membership in a sense.\"}, {\"type\":\"paragraph\",\"text\":\"Not on the client side though.\"}, {\"type\":\"paragraph\",\"text\":\"Sure. All I\u2019m getting at is that it seems like we are trying to replicate the Tor network, or a subset, it just seems that\u2019s a lot to bite off basically. Maybe we\u2019ll get there when we get there. We\u2019d just end up with VPNs over Lightning. That sounds cool, I thought that was cool a few years ago, I did talks and stuff but now I\u2019m more wary of it.\"}, {\"type\":\"paragraph\",\"text\":\"The point is that yes you have to rate limit, if someone tries to spam you with 100MB a second of onion messages you will rate limit them and tell them to shut up. But if you could flow that flow control back to the source then you\u2019re not as strictly impacting the quality of service for others. You can actually push the flow control back through honest nodes to the border where you have some node\u2026\"}, {\"type\":\"paragraph\",\"text\":\"There is no sybil resistance here because the attacker could just create another ID. If we are not rate limiting people who don\u2019t have a channel, creating new node IDs and just sending anonymous messages is really easy. That goes back to accepting onion messages from people who have channels. Another thing that I wanted to mention is we need to think about what is the degraded. In most cases that we want to use onion messages for the degradation of service when you just drop the onion messages would just mean that you may be losing privacy by having to connect directly, one hop through your ISP instead of a longer route, but that is probably acceptable in most cases right?\"}, {\"type\":\"paragraph\",\"text\":\"The streaming movies thing is kind of interesting. It depends how our rate limiting is. If our rate limiting is relatively aggressive\u2026. You basically want one message back and forth generally, You are very low actual requirements. Your rate limiting can be fairly aggressive. It will be interesting to see if we see massive amounts of abuse. We\u2019ve seen some HTLC abuse.\"}, {\"type\":\"paragraph\",\"text\":\"It seems like botnets are going to love this thing.\"}, {\"type\":\"paragraph\",\"text\":\"Botnets can use HTLCs though, they can use failed HTLCs for confs and we haven\u2019t seen that yet.\"}, {\"type\":\"paragraph\",\"text\":\"Botnets do use Tor, they use all kinds of other stuff.\"}, {\"type\":\"paragraph\",\"text\":\"I understand that. It just seems like to me we are just adopting this other network type due to necessity. I am just afraid what happens in future.\"}, {\"type\":\"paragraph\",\"text\":\"If you require a channel no botnet is going to use this because no botnet is going to open a channel at each endpoint of the botnet.\"}, {\"type\":\"paragraph\",\"text\":\"I like your monetization strategy, that\u2019s awesome.\"}, {\"type\":\"paragraph\",\"text\":\"I\u2019m just caught on the arbitrary data thing. The implications of that, whether it is things that we like or we don\u2019t like, what people can use it for in the future, the tension that can draw. I understand it is super useful for other stuff but I\u2019m just worried about the tail end of it. Maybe it is not going to happen.\"}, {\"type\":\"paragraph\",\"text\":\"I think we\u2019ve built that already unfortunately. HTLCs built that already.\"}, {\"type\":\"paragraph\",\"text\":\"Onion messages are no more or less s\\\\*\\\\*\\\\*\\\\*y. The only difference with an onion message assuming proper rate limiting like we described is you have to pay maybe a 100 msat fee or 1 sat fee. That is the only difference. And you get much smarter rate limiting for onion messages because you can push the rate limiting back towards the sender.\"}, {\"type\":\"paragraph\",\"text\":\"I\u2019m not very optimistic, I guess we\u2019ll see where it goes. I guess people will handle it when we get Wireguard over Lightning. That sounds cool.\"}, {\"type\":\"paragraph\",\"text\":\"I do anticipate at some point that we will see people paying for HORNET. There are definitely going to be LSPs, people who run Lightning nodes and are quite happy to sell you bandwidth. I expect that this rate limiting will become too aggressive for that kind of usage. It will be interesting to see where people set the rate limits.\"}, {\"type\":\"paragraph\",\"text\":\"Have people implemented the rate limiting today or just hypothesizing how it could be done in the future?\"}, {\"type\":\"paragraph\",\"text\":\"No we are handwaving, I haven\u2019t rate limited. There is a FIXME in the code, you should rate limit here.\"}, {\"type\":\"paragraph\",\"text\":\"I assume before shipping people will have naive rate limiting. The previous discussion of being able to tell the peer to shut up and slow down is something that would need to be spec\u2019ed in the future.\"}, {\"type\":\"paragraph\",\"text\":\"Payment flow control and data flow control, I don\u2019t know. It seems like a lot but that\u2019s just me maybe.\"}, {\"type\":\"paragraph\",\"text\":\"At least data flow control is easy.\"}, {\"type\":\"paragraph\",\"text\":\"But it is something else entirely.\"}, {\"type\":\"paragraph\",\"text\":\"Who do you rate limit if you get your limit on two paths? You send to both, you go \u201cI\u2019m rate limiting you by the way.\u201d When it goes in the outgoing you\u2019d go \u201cThat\u2019s rate limited. I am going to push back and say by the way you\u2019re rate limited.\u201d And that flows back indefinitely. In effect yes you\u2019d end up degrading the entire network down to your rate limit but that\u2019s a feature if you are flooding the entire network.\u201d The question of can I jam an uninvolved party at very small cost, you can jam in the sense that you can send them lots of traffic and they can start rate limiting traffic. That\u2019s way, way better than them jamming your HTLCs where they jam your ability to make payments. This is the OP_RETURN argument. It is far worse for them to spam you with HTLCs so you provide them with this low overhead method of sending stuff so they don\u2019t do the worst thing.\"}, {\"type\":\"paragraph\",\"text\":\"I guess we\u2019ll see how it develops.\"}, {\"type\":\"paragraph\",\"text\":\"I don\u2019t think we\u2019re making any progress here so we should move on.\"}, {\"type\":\"heading\",\"text\":\"Add payment metadata to payment request\"}, {\"type\":\"paragraph\",\"text\":\"<https://github.com/lightning/bolts/pull/912>\"}, {\"type\":\"paragraph\",\"text\":\"PR 912, the current state, it looks like there are a few updates. Christian posted an update 42 minutes ago, Christian is doing the normal thing of contributing to the spec on meeting day, thanks Christian.\"}, {\"type\":\"paragraph\",\"text\":\"It is just a minor formatting\u2026\"}, {\"type\":\"paragraph\",\"text\":\"There is some formatting discussions on the thing, I think I had a similar formatting discussion comment. It looks like there is one implementation from the eclair folks, t-bast had something.\"}, {\"type\":\"paragraph\",\"text\":\"LND also has send and receive in a PR.\"}, {\"type\":\"paragraph\",\"text\":\"It looks like it is just pending resolution of some spec update comments that can happen on GitHub and then cross implementation tests. Are there any comments that need higher bandwidth discussion that should come up now? Or can we resolve everything on GitHub?\"}, {\"type\":\"paragraph\",\"text\":\"It is interesting that LDK is doing this already, just with the payment secret but there is an immediate use for this, that is quite nice.\"}, {\"type\":\"paragraph\",\"text\":\"Yeah it turns out on the LDK end we don\u2019t need a whole lot of data so we are just going to do this today with the payment secret. We don\u2019t need more data.\"}, {\"type\":\"paragraph\",\"text\":\"If you want to do just in time insertion of invoices and just replicate the invoice as if you already had it in the database then inside that payment metadata you need to put all the fields that were used to create the invoice, the invoice you didn\u2019t store, so you can recreate it when the payment actually comes in. How is this going to work out? Is every implementation going to\u2026\"}, {\"type\":\"paragraph\",\"text\":\"On the LDK end we are not talking about doing that. LDK splits the responsibilities there. We handle authenticating the payment which is the standard payment secret concept and then we let the user deal with storing actual concrete metadata. Description and all that kind of stuff. We anticipate with our change that users will still actually store data about the payment in their own local database but that is outside of the scope of LDK. LDK will generate payment secrets such that we can authenticate the payment by amount and authenticate it with the sender. We don\u2019t actually do anything else, that is not our job.\"}, {\"type\":\"paragraph\",\"text\":\"If you want to take that one step further and you also don\u2019t want to have this user database, that is possible as well with this. Everything in the metadata, you can just insert it on the fly. It is very stateless, it is also very cheap. You can generate as many invoices as you want. If they don\u2019t pay they don\u2019t take up any space. There is no expiration. Will something be standardized or will a loose standard emerge on how to do this? Maybe if we copy over\u2026\"}, {\"type\":\"paragraph\",\"text\":\"Something, something bLIP or SPARK, whatever people want to call it.\"}, {\"type\":\"paragraph\",\"text\":\"I think it depends on what the emergent use cases will be. Maybe it is going to take an initial iteration but it is non-binding which is cool.\"}, {\"type\":\"paragraph\",\"text\":\"Maybe in hindsight we should have made the payment secret of variable length. Now at least we are forcing to be some kind of random number so maybe it is safer.\"}, {\"type\":\"paragraph\",\"text\":\"It should be variable size. That is something I regret.\"}, {\"type\":\"paragraph\",\"text\":\"We did discuss it at some point but then we said it is too dangerous, people will use one byte and then it is not secret anymore, something like that.\"}, {\"type\":\"heading\",\"text\":\"Advertize compression algorithms in init\"}, {\"type\":\"paragraph\",\"text\":\"<https://github.com/lightning/bolts/pull/825>\"}, {\"type\":\"paragraph\",\"text\":\"t-bast and I were communicated a little bit about doing some cross implementation tests. I have a testnet node with this up, I think t-bast has too but I was too lazy to setup my testnet to support Tor. It does need a rebase and it looks like Vincenzo has some comments on GitHub which should be resolved on GitHub. Is there anything that needs high bandwidth discussion and should be discussed here? Ok, follow up on GitHub, we will introduce some cross implementation tests on that soon as well.\"}, {\"type\":\"heading\",\"text\":\"Dynamic DNS support in gossip messages\"}, {\"type\":\"paragraph\",\"text\":\"<https://github.com/lightning/bolts/pull/911>\"}, {\"type\":\"paragraph\",\"text\":\"<https://github.com/lightning/bolts/pull/917>\"}, {\"type\":\"paragraph\",\"text\":\"Next we\u2019ve got these two PRs for gossip addresses, DNS hostname and to tell your peer what IPs you have when you connect. Are there implementations of this? Or is it still just theoretical?\"}, {\"type\":\"paragraph\",\"text\":\"The IP one, there is a c-lightning and eclair implementation but last I tested I don\u2019t remember, I think I sent some comments to m-schmoock because there were issues that I found in the c-lightning implementation. I don\u2019t know if that has been fixed since then.\"}, {\"type\":\"paragraph\",\"text\":\"It is still a pull request, we haven\u2019t merged it yet. Unfortunately Michael is not on the call. It is still a work in progress as I understand it but the spec seems pretty straightforward.\"}, {\"type\":\"paragraph\",\"text\":\"Sounds like c-lightning and ACINQ are working on cross implementation testing and nothing worth discussing here.\"}, {\"type\":\"heading\",\"text\":\"BOLT 2 and BOLT 9: introduce feature bit to gate new channel_type feature\"}, {\"type\":\"paragraph\",\"text\":\"<https://github.com/lightning/bolts/pull/906>\"}, {\"type\":\"paragraph\",\"text\":\"We shipped something that messed up, PR 906 basically, this is the feature bit one. I think we all interpret the presence of the feature bit and sending the value slightly differently. In a way that works sometimes and doesn\u2019t work other times. I am getting some reports, I think y\u2019all always require the channel type to set if the feature bits are there right? You respond with one even if we didn\u2019t send one? I just want to make sure that is the fix.\"}, {\"type\":\"paragraph\",\"text\":\"We always spawn with one because it is an odd TLV even if you didn\u2019t set the bit or didn\u2019t send anything, we are going to respond with something.\"}, {\"type\":\"paragraph\",\"text\":\"But what are you going to respond with if I didn\u2019t send anything?\"}, {\"type\":\"paragraph\",\"text\":\"What we are going to use, what will automatically picked up by the normal feature bit negotiation.\"}, {\"type\":\"paragraph\",\"text\":\"I see. You are sending the implicit one even if I didn\u2019t send one?\"}, {\"type\":\"paragraph\",\"text\":\"Yeah exactly.\"}, {\"type\":\"paragraph\",\"text\":\"I think we don\u2019t like that because we didn\u2019t choose anything and we exit out there.\"}, {\"type\":\"paragraph\",\"text\":\"We figured it is just making it explicit something that was implicit. The other side can just ignore so I thought it was a win. It was less code because we just send it all the time.\"}, {\"type\":\"paragraph\",\"text\":\"If you didn\u2019t advertise this feature bit you should be ignoring.\"}, {\"type\":\"paragraph\",\"text\":\"c-lightning does that as well too right? Ok we can fix that.\"}, {\"type\":\"paragraph\",\"text\":\"There is also a comment on the PR 906. Right now you don\u2019t ignore obviously if you receive a channel type even though the feature bit is not set, the feature bit doesn\u2019t exist yet because the PR is not merged. The PR currently says that you should ignore the channel type if the feature bit was not set. I commented and t-bast seems to agree that you should continue to optionally interpret the TLV whether the feature bit is set or not. In part because nodes do this today.\"}, {\"type\":\"paragraph\",\"text\":\"Don\u2019t feature bits gate inclusion of a TLV? If you are setting the TLV and I have the feature bit I wouldn\u2019t read it right?\"}, {\"type\":\"paragraph\",\"text\":\"You can read it if you want. It is there. It is used today, that is what the spec says today. I know LDK does that, I don\u2019t know what other people do. We send the TLV and we interpret the TLV whether there is a feature bit or not.\"}, {\"type\":\"paragraph\",\"text\":\"Interesting. We\u2019ll parse it but we\u2019ll ignore it. That seems like a different requirement. We\u2019ll only look at it if the feature bit is set.\"}, {\"type\":\"paragraph\",\"text\":\"If you want to not send a channel type in response then that would be fine too. My proposed change here is we\u2019ll send it, we\u2019ll parse it if we receive it, we don\u2019t care about the feature bit. And we\u2019ll also eventually now set the feature bit. But if you want to ignore the field because we didn\u2019t set the feature bit, you are talking to a current version of LDK, not a future version, then that\u2019s fine as long as you don\u2019t respond with a channel type in the accept channel message. We\u2019ll just say \u201cClearly they didn\u2019t understand it and that\u2019s fine\u201d.\"}, {\"type\":\"paragraph\",\"text\":\"I\u2019ll need to go back and read the original PR.\"}, {\"type\":\"paragraph\",\"text\":\"I see what you are saying. But if it is present in both messages and we only send it if it was present\u2026\"}, {\"type\":\"paragraph\",\"text\":\"The problem is what you are suggesting is a change from the current spec. The current spec says you should just send it and if you receive it you should parse it. If you understand it and you parse it you should respond with something in the accept channel message.\"}, {\"type\":\"paragraph\",\"text\":\"Currently it is gated on both sides.\"}, {\"type\":\"paragraph\",\"text\":\"It is making it slightly tighter yeah.\"}, {\"type\":\"paragraph\",\"text\":\"If we had done it the right way, if we\u2019d put a feature bit in the first place then it is pretty easy. Set the feature bit and send it. If you don\u2019t set the feature bit don\u2019t send it. And then it is very easy. But we didn\u2019t do that. Now it is kind of implied, if you sent it that means you wanted me to use it. If we both send it then we\u2019re using it. If we didn\u2019t both send it then we\u2019re not using it at all.\"}, {\"type\":\"paragraph\",\"text\":\"I think it is compatible with the behavior in that if I\u2019m sending the bit I\u2019m going to send it. I can remove that to make that looser but I think it is compatible with our behavior of we only send it if we send a bit.\"}, {\"type\":\"paragraph\",\"text\":\"The proposed change makes existing implementations do something that they must not do.\"}, {\"type\":\"paragraph\",\"text\":\"They won\u2019t set the bit but they will send it.\"}, {\"type\":\"paragraph\",\"text\":\"They won\u2019t set the bit and they will send it. The proposed change makes that something you are not supposed to do.\"}, {\"type\":\"paragraph\",\"text\":\"I can fix that super easily. I think I found the source of that other bug. I think there is another one with eclair but I\u2019ll message you about that t-bast. Then we can hopefully do the part release.\"}, {\"type\":\"paragraph\",\"text\":\"I need to reread the full text but my intuition is that it would still be the case whether the feature bit is set or not, if one node sends the TLV and the other node sends back the TLV in the accept channel then you\u2019re using the TLV whether the feature bit is set or not. If a node wants to gate responding with the TLV on the feature bit they can do that, that\u2019s totally fine. But if both TLVs are there you are using them whether the feature bit is set or not.\"}, {\"type\":\"paragraph\",\"text\":\"I see what you are saying. We arrived at that conclusion to set the bit differently but you\u2019re right. If both people set the type we\u2019re using it.\"}, {\"type\":\"paragraph\",\"text\":\"I just wanted to make sure, that would be the current behavior.\"}, {\"type\":\"paragraph\",\"text\":\"After this gets merged and everyone has updated then everyone will set the feature and everyone will send the thing. It is a future point if you didn\u2019t set the feature you wouldn\u2019t send the thing.\"}, {\"type\":\"paragraph\",\"text\":\"I think that\u2019s the other error that we are seeing here. Interoperability testing will figure it out.\"}, {\"type\":\"heading\",\"text\":\"Simple turbo channels enablement\"}, {\"type\":\"paragraph\",\"text\":\"<https://github.com/lightning/bolts/pull/910>\"}, {\"type\":\"paragraph\",\"text\":\"Turbo channels, PR 910, are there implementations of this? We\u2019re working on it, we\u2019re getting there.\"}, {\"type\":\"paragraph\",\"text\":\"I think Eugene has one now that he has tested. I think there are just questions on chantype stuff. We are talking about zero conf.\"}, {\"type\":\"paragraph\",\"text\":\"My only concern was there is no chantype for zero conf explicitly. I left a comment.\"}, {\"type\":\"paragraph\",\"text\":\"Zero conf isn\u2019t a different channel construction, it is not really something you have to remember. Originally channel types were stuff you had to remember. \u201cThis is a static remote key\u201d or stuff that was obviously persisting across the channel. There is one thing however you have to remember. If this is a private channel and you don\u2019t want them to route by the short channel ID\u2026 Let me pull up the PR, I should mention turbo in the title then I could find more easily. I think the last commit may have added this, there is a pile of 8 fixes. Now there is a channel type but that channel type means don\u2019t you dare route by short channel ID. That\u2019s cool and the reason that is cool is because when we have channel type upgrade, which is another PR, you can take the existing private channel and then go \u201cFrom now on no longer route via short channel ID. We are going to use the alias thing now.\u201d For a normal channel you can route by both. I can give you an alias and you can use either. But obviously for an unannounced channel in the ideal world you would never route by short channel ID to avoid probing. You can\u2019t do that today because it breaks back compatibility. You don\u2019t know when the other side is ready. They have got to be handing out aliases in their invoices and stuff like that. By adding a short channel ID just for the private case that gives you that feature that you want.\"}, {\"type\":\"paragraph\",\"text\":\"I saw the recent change. I was mostly referring to if I start a channel flow and I have the feature bit and they have the feature bit, they want zero conf. When the acceptor sends accept channel it is kind of like \u201cI hope you open a zero conf channel to me. I hope you send `funding_locked`.\u201d In the spec currently if a `funding_created` is sent back then the initiator agrees to open a zero conf channel, a promise almost. The current wording is very open ended I think.\"}, {\"type\":\"paragraph\",\"text\":\"We should make it clear that if you offer this ability and you are funding the channel then you should do zero conf. You\u2019ve got nothing to lose, I trust myself so I will zero conf for you. Whether you accept it or not is obviously beyond my control. You might decide to delay for some confs. But the opener should always send, I\u2019ll check the wording. The idea is to prefer this model of opening in future. If you advertise this you will aggressively send `funding_locked` before it is really locked. I will check the wording to make sure that is explicit enough.\"}, {\"type\":\"paragraph\",\"text\":\"His point is he preferred to be more explicit. Y\u2019all are saying they don\u2019t have to send it. We\u2019d like to make that explicit.\"}, {\"type\":\"paragraph\",\"text\":\"There are two things here. One is do I trust you? There is a whole trust question. Am I prepared to let you open a zero conf channel and route stuff and accept payments and everything else? I am not quite clear how you would do that, that decision may come later.\"}, {\"type\":\"paragraph\",\"text\":\"That decision is entirely out of band basically. It almost doesn\u2019t need to be in the protocol because do I trust you is a question that is going to be decided entirely out of band via some mechanism of either talking to someone if it is a regular node or some LSP, whatever that system is. It being in the protocol doesn\u2019t seem to add very much because they already know who they are talking to, they already have some special protocol.\"}, {\"type\":\"paragraph\",\"text\":\"You\u2019ll start bouncing HTLCs off.\"}, {\"type\":\"paragraph\",\"text\":\"Does that mean you can\u2019t signal it within the protocol? Otherwise every party opening a channel with me if I have the feature bit set is somehow assuming that I may send it. Versus if I am opening a channel outbound and I don\u2019t set the bit they know we are not doing zero conf. To me it is about the explicit versus implicit type of thing. Do we implicitly know because I don\u2019t know who Matt actually is in real life that we are not doing zero conf? Or can I set in my message \u201cHey we are doing a zero conf\u201d.\"}, {\"type\":\"paragraph\",\"text\":\"It seems like you are trying to interpret the bit in a way that the bit doesn\u2019t mean. The bit does not mean zero conf. That\u2019s not what the bit means.\"}, {\"type\":\"paragraph\",\"text\":\"I think the difference is that y\u2019all are interpreting it as behavior while we\u2019re thinking of it as a channel type. If we can add logic to validate that channel type and let users explicitly open that channel type. Y\u2019all are saying \u201cI have the bit set. I might send it, I might not\u201d.\"}, {\"type\":\"paragraph\",\"text\":\"I think the UX will be other way round. Matt opens a channel with me and then he pings me and goes \u201cYou don\u2019t trust my node yet, I can\u2019t route through you\u201d and I go \u201cCool, I am going to flip that on\u201d. There is no way to change the channel type after we\u2019ve negotiated it. It depends how your controls are going to work. If beforehand you are going to have a vetted list of nodes that you trust then when we\u2019re talking obviously in the protocol I could say \u201cBy the way I am perfectly happy to open this zero conf with you\u201d. When you open a channel with me I go \u201cYeah I trust you\u201d and you know. But I don\u2019t know how that would extend to the case where after you\u2019ve opened the channel with me I decide that I trust you and I\u2019m going to do the thing.\"}, {\"type\":\"paragraph\",\"text\":\"We\u2019re talking about two different feature bits here. Y\u2019all have the option SID but we\u2019re thinking of another funding level bit basically.\"}, {\"type\":\"paragraph\",\"text\":\"Yes. You are proposing adding another feature bit.\"}, {\"type\":\"paragraph\",\"text\":\"I was talking about a channel type.\"}, {\"type\":\"paragraph\",\"text\":\"Which is a bit in this case with the way that it is set up.\"}, {\"type\":\"paragraph\",\"text\":\"It would technically be the same.\"}, {\"type\":\"paragraph\",\"text\":\"Was your suggestion that if `funding_created` is sent back in response to `min_depth=0` that the initiator promises to open a zero conf?\"}, {\"type\":\"paragraph\",\"text\":\"You shouldn\u2019t be promising to open a zero conf in the spec.\"}, {\"type\":\"paragraph\",\"text\":\"If you set `min_depth` as zero then you\u2019re saying you\u2019re good. At the moment the opener says \u201cI want to open this channel\u201d and the acceptor says \u201cHere\u2019s my min depth\u201d and usually that is 3 or whatever. If I trust you I would set that to zero and it says that in the spec. Set that to zero implying that I\u2019m ready to go whenever, as fast as the message can get through I will trust your channel. We do have a flag explicitly in the protocol, a way of saying \u201cI trust you\u201d. On the other side we are saying you should always open zero conf. If you are the one doing the opening you should `funding_locked` aggressively immediately because you are signaling that you are all good. It is the receiver side, the acceptor side, in that case we do have a method of you saying \u201cYes I want this to be a zero conf channel\u201d. Now we could also put it in a channel type somewhere but what I am saying is I think in a lot of use cases it is going to posthoc. After you\u2019ve opened the channel you will suddenly decide that you want it to be zero conf. There\u2019s no really good way of doing that. The way to do that is you actually send the `funding_locked` early. You might have set `min_depth` as 3 but that is a hint.\"}, {\"type\":\"paragraph\",\"text\":\"Two things, we have something in mind basically where we\u2019ll know ahead of time, not the after the fact thing. It seems like the flow is different, you are thinking about it differently. Right now the acceptor sends `min_depth` meaning the initiator can\u2019t say \u201cLet\u2019s open a zero conf\u201d. The acceptor says \u201cI\u2019m going to make it zero conf\u201d. I think that is the control flow we want to flip basically. To allow the initiator to say \u201cI\u2019m going with zero conf\u201d which also lets the acceptor assert that this is going to be zero conf and they\u2019ve opted into it as well.\"}, {\"type\":\"paragraph\",\"text\":\"In the future the sender will always open zero conf, always. Every channel will be zero conf, everyone will be zero conf. There is no non zero conf anymore. \u201cHere\u2019s the feature, I support zero conf\u201d.\"}, {\"type\":\"paragraph\",\"text\":\"Moving to full RBF in v24, full RBF and zero conf everywhere don\u2019t really go together super great.\"}, {\"type\":\"paragraph\",\"text\":\"For channel v2 stuff?\"}, {\"type\":\"paragraph\",\"text\":\"Bitcoin Core is planning to ship in v24 full RBF, so every transaction is RBFable. Rusty\u2019s point is that the initiator knows that they are not going to RBF and that\u2019s totally on the initiator\u2019s side. The receiver is the one who has to decide do I trust you to not RBF or do I set it at some `min_conf`.\"}, {\"type\":\"paragraph\",\"text\":\"It just feels like the control flow should be flipped. Let\u2019s say I\u2019m opening a zero conf with Rusty and he doesn\u2019t like me. I send `open` with chantype zero conf or the bit, whatever else, and he sends me the `reject` and now we know. There is no ambiguity of \u201cI opened it. I want a zero conf. Is he going to go first?\u201d I think we\u2019re trying to eliminate the ambiguity. The initiator says \u201cWe\u2019re doing it\u201d and then they deny immediately. Otherwise you are in some limbo. Are they going to send it or are they not? \u201cI guess they didn\u2019t send it, too bad\u201d. We think with the protocol we have in mind not having this explicit thing in there makes it hard to reason about what is going to happen. I feel like we have different use cases in mind. You are thinking \u201cAfter the fact we decide to make it zero conf\u201d while we\u2019re thinking \u201cWe are setup to do a zero conf channel\u201d.\"}, {\"type\":\"paragraph\",\"text\":\"You are not going to accept zero conf from anyone.\"}, {\"type\":\"paragraph\",\"text\":\"Yes, which is why you\u2019ll send the `reject` message.\"}, {\"type\":\"paragraph\",\"text\":\"The point is no one is going to say \u201cI accept this from everyone\u201d and so there is always going to be some out of band negotiation.\"}, {\"type\":\"paragraph\",\"text\":\"You are assuming a lot about how that negotiation will take place. Rusty is assuming that the negotiation will take place after we already opened the channel\u2026\"}, {\"type\":\"paragraph\",\"text\":\"No I wanted to allow that.\"}, {\"type\":\"paragraph\",\"text\":\"I am just assuming there will be a negotiation. There doesn\u2019t need to be anything in the protocol at that point. There is implicitly.\"}, {\"type\":\"paragraph\",\"text\":\"If people are doing it like that today, we are trying to add something in the protocol.\"}, {\"type\":\"paragraph\",\"text\":\"You can\u2019t get away from that. You can add as much as you want to the protocol, there will still be some kind of out of band negotiation to say \u201cHey can you mark my node as trusted so I can open a zero conf channel with you\u201d. At that point I don\u2019t need it in the protocol.\"}, {\"type\":\"paragraph\",\"text\":\"Sure, but right now what doesn\u2019t exist direct feedback or explicit acknowledgement of that relationship within the protocol.\"}, {\"type\":\"paragraph\",\"text\":\"There is, if they reply with `min_depth=0` that means they have accepted that they are ready to go with a zero conf channel. But it is not in the channel type.\"}, {\"type\":\"paragraph\",\"text\":\"It is basically a delayed three way handshake. I send it, you send something\u2026 versus me just sending it.\"}, {\"type\":\"paragraph\",\"text\":\"No you send that at the same time you send the channel type, it is literally in the same package I think.\"}, {\"type\":\"paragraph\",\"text\":\"But the responder sends `min_depth`.\"}, {\"type\":\"paragraph\",\"text\":\"They would also send the channel type.\"}, {\"type\":\"paragraph\",\"text\":\"The difference is me the initiator, I can\u2019t initiate a zero conf and then have you accept or deny it. You denying it is basically you sending the error message or the warning.\"}, {\"type\":\"paragraph\",\"text\":\"But it is the same message flow.\"}, {\"type\":\"paragraph\",\"text\":\"It is not the same message flow.\"}, {\"type\":\"paragraph\",\"text\":\"The difference is that instead of the acceptor failing it you would then fail it. The opener would then reject and go \u201cNo you didn\u2019t put a zero min_depth so I\u2019m not going to open this with you\u201d. Is there a case where you would want to not fallback to a non-zero?\"}, {\"type\":\"paragraph\",\"text\":\"Yes. We have a specific use case. If it is not zero conf we\u2019re not doing it because we wanted zero conf as the initiator.\"}, {\"type\":\"paragraph\",\"text\":\"But you don\u2019t need a feature bit for that either. What you are saying is you want a feature bit so that instead of an `accept_channel` message the receiver immediately sends an error message. You don\u2019t necessarily need to do that immediately, they can send that `accept_channel` and then the initiator can send back an error instead of moving forward.\"}, {\"type\":\"paragraph\",\"text\":\"You want them to send an accept and an error?\"}, {\"type\":\"paragraph\",\"text\":\"No, not the receiver. The receiver sends the accept and the initiator says \u201cWhoa, that funding_locked is not zero, I don\u2019t want to do this\u201d, sends an error, closes the channel and moves on. You don\u2019t need a new feature bit to do that. You can accomplish that by just sending an error message.\"}, {\"type\":\"paragraph\",\"text\":\"It is a different way of doing it. Philosophically maybe I\u2019m the odd one, I like things to be explicit on the protocol level.\"}, {\"type\":\"paragraph\",\"text\":\"The only thing I dislike about the channel type is that the channel type is persistent across the channel. In the long term it doesn\u2019t matter whether it was zero conf. It is a weird thing to put in the channel type. Using the message depth to indicate whether you are accepting zero conf or not\u2026\"}, {\"type\":\"paragraph\",\"text\":\"You could delete the bit, you could keep it in memory, I don\u2019t know.\"}, {\"type\":\"paragraph\",\"text\":\"What do you think about the fact also that even if I tell you it is zero I can switch all my `funding_locked` and make it non-zero afterwards. You\u2019re not going to close that channel on me because we just went through the trouble of opening it.\"}, {\"type\":\"paragraph\",\"text\":\"You can always accept the open and then refuse to route or accept any HTLCs too.\"}, {\"type\":\"paragraph\",\"text\":\"I feel like you can do a bunch of things. We are just trying to make things explicit for the computers and they know what we\u2019re doing. We have to handle all the extraneous cases where you do some random thing because you are buggy still. We are literally talking about a bit. You already store the bit.\"}, {\"type\":\"paragraph\",\"text\":\"It has to be another one because I stole this feature bit to mean something else. I stole the feature bit to mean don\u2019t route into the channel type already.\"}, {\"type\":\"paragraph\",\"text\":\"There are two different things. We are just talking about making the negotiation explicit basically. We can write down this flow as well to make it more clear.\"}, {\"type\":\"paragraph\",\"text\":\"We are all on the same page, I just don\u2019t buy that that is more explicit. I totally understand what you are saying. I don\u2019t buy that that is materially more explicit. Users don\u2019t see \u201cChannel closed with reason channel failed to open because you didn\u2019t accept zero conf\u201d. At the end of the day the user experience is still you see the same error message and the same failure reason.\"}, {\"type\":\"paragraph\",\"text\":\"You are assuming a lot about how negotiation will work in general, how out of bounds stuff will work in general.\"}, {\"type\":\"paragraph\",\"text\":\"The spec explicitly says if you trust them you should set the depth to zero. If they don\u2019t do that you go \u201cYou don\u2019t trust me so I\u2019m going to close the channel. I\u2019m not going to continue opening.\u201d We already have a flag, it is just that it is not in the channel type. If you put it in the channel type the failure is faster.\"}, {\"type\":\"paragraph\",\"text\":\"It fails faster by one packet.\"}, {\"type\":\"paragraph\",\"text\":\"Yes. That\u2019s lovely. Why do we have TCP Fast Open? It is one more round trip.\"}, {\"type\":\"paragraph\",\"text\":\"On the downside this would be worse for us because we will open everything zero conf and we want to fallback. We will have to reopen, \u201cThat\u2019s right, you didn\u2019t accept the zero conf channel type.\u201d Every time we would have to try again with the non-zero conf variant of the channel type. It is a lot more work for everyone else.\"}, {\"type\":\"paragraph\",\"text\":\"You seem to be living in a universe where everything is zero conf everywhere. We\u2019re like \u201cIt is going to be zero conf if both sides cross the t or sign here basically\u201d. I think we are looking at it differently in that regard as well.\"}, {\"type\":\"paragraph\",\"text\":\"We will be offering zero conf to everyone.\"}, {\"type\":\"paragraph\",\"text\":\"And we wouldn\u2019t. We\u2019d only do it under very specific situations.\"}, {\"type\":\"paragraph\",\"text\":\"Why?\"}, {\"type\":\"paragraph\",\"text\":\"Or one side setting it explicitly.\"}, {\"type\":\"paragraph\",\"text\":\"The receiver can always immediately send a `funding_locked`. Now you\u2019re sitting on your `funding_locked` for no reason.\"}, {\"type\":\"paragraph\",\"text\":\"We wouldn\u2019t do anything because we didn\u2019t set the bit. This is just constraining the paths of the software and what we expect. It seems like people at least acknowledge that there\u2019s a condition where maybe you want the initiator to be able to specify this upfront. And it fails faster. At least we have those two acknowledgements. We won\u2019t be setting zero conf for everything once this is in as well too.\"}, {\"type\":\"paragraph\",\"text\":\"We will. So we definitely do not want your dance where you have to reconnect and offer a different channel type. That is why. It is a lot more logic for us to change this.\"}, {\"type\":\"paragraph\",\"text\":\"It is still implementation phase.\"}, {\"type\":\"paragraph\",\"text\":\"More code in exchange for half a RTT, faster failure does not seem like it is\u2026\"}, {\"type\":\"paragraph\",\"text\":\"You\u2019re trivializing the implicit versus explicit thing. More code is super relative.\"}, {\"type\":\"paragraph\",\"text\":\"It is still explicit. There is still an error message, it is still incredibly explicit. If you interpret the bytes on the wire in the way described in the spec it is equally explicit in both cases.\"}, {\"type\":\"paragraph\",\"text\":\"Comment: Making the \u201cwe always open zero conf\u201d much harder in exchange for a tiny speed improvement for those that don\u2019t should make the `channel_type` undesirable. 1/2 RTT in exchange for 4 RTT for a reconnect.\"}, {\"type\":\"paragraph\",\"text\":\"Are you really going to do everything zero conf after this?\"}, {\"type\":\"paragraph\",\"text\":\"Why not?\"}, {\"type\":\"paragraph\",\"text\":\"You can\u2019t really do that with 2 player channels. Anything that uses an interactive protocol, you start getting into trouble.\"}, {\"type\":\"paragraph\",\"text\":\"That is unspec-ed so far. We need to figure that out. Once the other party is putting funds in you cannot default to zero conf without a trust relationship. But in this case of simple open this is very simple. One side has nothing to lose by offering zero conf. In the case of simple open that is the funder.\"}, {\"type\":\"paragraph\",\"text\":\"If I said on Reddit every channel is now zero conf people will be like what?\"}, {\"type\":\"paragraph\",\"text\":\"On the initiator side I agree that the initiator has an incentive to always say zero conf. If he\u2019s the only one putting funds in the channel on the receiver side I agree that we would choose depending on other conditions. But on the initiator side I don\u2019t see why we would not do zero conf all the time.\"}, {\"type\":\"paragraph\",\"text\":\"The initiator might not just auto do zero conf because the market may price that default risk? If you have no marginal cost then you would but if there is a market premium for that service from an acceptor\u2026\"}, {\"type\":\"paragraph\",\"text\":\"Again that negotiation happens out of band. If you have an out of band price for accepting a zero conf then presumably that will be you have to set at least a `push_msat` of x in order for me to accept your zero conf. But if I just request a zero conf and set a `push_msat` below that you simply won\u2019t accept it and that\u2019s fine. You still do it at the protocol level because why not?\"}, {\"type\":\"paragraph\",\"text\":\"I guess we just have different ways of looking at this risk, the feature itself and negotiation.\"}, {\"type\":\"paragraph\",\"text\":\"What risk?\"}, {\"type\":\"paragraph\",\"text\":\"I just want to make it explicit. I want to make sure that both sides are double opting in to this zero conf type thing. I send the feature bit, you decline. It is fast close. It does get in the way of this every zero conf thing. I don\u2019t know if that is a good idea. Maybe that is just simpler, to do zero conf all day, every day.\"}, {\"type\":\"paragraph\",\"text\":\"Way simpler.\"}, {\"type\":\"paragraph\",\"text\":\"Even from our perspective after implementing this code, is it just gating this new behavior?\"}, {\"type\":\"paragraph\",\"text\":\"Even if we don\u2019t go there zero conf for everything having the ability to open a zero conf without having to first check with the node whether they would accept it is something that we need to have. If we end up aborting a fund channel because our counterparty did not accept the zero conf then we have to reconnect, that\u2019s way more code than the optimization we gain from closing half a roundtrip earlier.\"}, {\"type\":\"paragraph\",\"text\":\"Yeah we won\u2019t be doing that, that is dumb.\"}, {\"type\":\"paragraph\",\"text\":\"We won\u2019t be doing zero conf all day everyday.\"}, {\"type\":\"paragraph\",\"text\":\"Why would you possibly not offer this?\"}, {\"type\":\"paragraph\",\"text\":\"Because we want to make it explicit to the users.\"}, {\"type\":\"paragraph\",\"text\":\"In the current spec you can choose to not opt in.\"}, {\"type\":\"paragraph\",\"text\":\"The difference is y\u2019all won\u2019t be able to open it up and then find out after the fact if they accept it. From the receiver standpoint.\"}, {\"type\":\"paragraph\",\"text\":\"You do it by error, we do it by examining a field. It is the same thing.\"}, {\"type\":\"paragraph\",\"text\":\"I want to be able to open up a channel without knowing if the relationship exists already. I find out once they get the open.\"}, {\"type\":\"paragraph\",\"text\":\"We want to try to open a zero conf channel. Our counterparty says \u201cNo go away\u201d. We have to reconnect, remember across these connections that they didn\u2019t accept it and retry without zero conf. That is way harder than just saying \u201cCan we try opening a zero conf?\u201d and the other side then says \u201cI don\u2019t want to\u201d and we are still good. We can\u2019t do better than falling back into a non-zero conf channel after trying a zero conf channel.\"}, {\"type\":\"paragraph\",\"text\":\"If we really wanted to do zero conf when they return with `min_depth` not equal zero we go \u201cNo sorry you are not zero conf enough for us. We only like zero conf things. We want people to trust us or whatever.\u201d We send an error at that point. I cannot imagine that it is priced except in a negative sense. c-lightning always offers zero conf and I can use it if I want and lnd doesn\u2019t.\"}, {\"type\":\"paragraph\",\"text\":\"Do you all agree that the acceptor is the person taking on risk?\"}, {\"type\":\"paragraph\",\"text\":\"Yes.\"}, {\"type\":\"paragraph\",\"text\":\"So they decide.\"}, {\"type\":\"paragraph\",\"text\":\"So why not let them be explicit with that?\"}, {\"type\":\"paragraph\",\"text\":\"We are by setting `min_depth`.\"}, {\"type\":\"paragraph\",\"text\":\"They say \u201cHere\u2019s my min_depth, it is not zero\u201d. That is how they are telling you explicitly whether they are going to zero conf or not.\"}, {\"type\":\"paragraph\",\"text\":\"Y\u2019all are saying this lets me open up a channel and not know if they support it yet and they tell me later. Versus me just saying \u201cI want to open the channel\u201d and they say \u201cNo\u201d. That\u2019s the difference.\"}, {\"type\":\"paragraph\",\"text\":\"Right because this is way simpler. You can offer it to everyone and they can accept or not on their own terms. You don\u2019t have to do this dance where you go \u201cI insist on a zero conf channel even though I don\u2019t care either way because it doesn\u2019t make a difference to me, I\u2019m opening it and I trust myself. I explicitly want to open a zero conf channel.\u201d They go \u201cNo I don\u2019t trust you\u201d. Then I go back and say \u201cNow let\u2019s open a normal channel\u201d. It is the dumbest protocol ever.\"}, {\"type\":\"paragraph\",\"text\":\"Do we realize that this is the type of negotiation that we put into place with the explicit channel type? Remember we had a different type before. There was this double opt in thing. We said \u201cNo you\u2019ll just send the error and then try again\u201d. That\u2019s what this is. We\u2019ll have to do that anyway for any channel type because that\u2019s the way we decided to do negotiation.\"}, {\"type\":\"paragraph\",\"text\":\"They are different. The reason I think it makes sense for channel type to try some specific channel type, \u201cI want this anchor thing\u201d and you say \u201cNo\u201d. I\u2019m like \u201cOk maybe something else\u201d. But here the reason it is different is that I really think when you actually use it if a guy says \u201cNo to zero conf\u201d you still want to have a channel with them.\"}, {\"type\":\"paragraph\",\"text\":\"But we described a case where that\u2019s not the case. We only want zero conf.\"}, {\"type\":\"paragraph\",\"text\":\"Then you send them an error going \u201cNo you didn\u2019t accept my zero conf\u201d.\"}, {\"type\":\"paragraph\",\"text\":\"You only want zero conf, it is for UX. Because otherwise the user opens it, they\u2019re waiting and maybe the wallet promised that they can send now but they can\u2019t because of this thing.\"}, {\"type\":\"paragraph\",\"text\":\"I don\u2019t think the gain of gaining half a RTT is worth it in that case. You just reject and not complete the flow. They say `min_depth` is not zero.\"}, {\"type\":\"paragraph\",\"text\":\"The opener would close in that case instead of the acceptor closing.\"}, {\"type\":\"paragraph\",\"text\":\"Yeah that\u2019s the difference.\"}, {\"type\":\"paragraph\",\"text\":\"The opener would go \u201cNo you are not zero conf enough for me. I only want channels with people who trust me\u201d and they error out at that point. I am really looking forward to zero conf everywhere. If you trust my node then sure we\u2019ll do zero conf and if you don\u2019t that\u2019s fine we\u2019ll be normal. But you still get the other features that we want here.\"}, {\"type\":\"paragraph\",\"text\":\"The other thing, this negotiation isn\u2019t what we all signed up for. The whole try it, reject and then try again.\"}, {\"type\":\"paragraph\",\"text\":\"No remember the original proposal was mine, it didn\u2019t have that and everyone was like \u201cWe can do that if this ever occurs\u201d. I went \u201cOk let\u2019s make sure one of them never occurs\u201d.\"}, {\"type\":\"paragraph\",\"text\":\"Do you remember the rationale? We were talking about how do you handle these weird feature bit combinations. I want anchors and something else that doesn\u2019t exist. How do we handle that? Just reject instead of both sides sending their overlap and then do it again.\"}, {\"type\":\"paragraph\",\"text\":\"Do we want to try another PR? I think this gets back to the longstanding disagreement about what feature bits are for and required for.\"}, {\"type\":\"paragraph\",\"text\":\"It comes up a lot, we really view the way negotiations work differently. It seems like every time we are like \u201cLet\u2019s add a feature bit\u201d there\u2019s this massive campaign of \u201cNo feature bits are bad and we don\u2019t want to do them. It is going to make the code more complex.\u201d When I thought the whole point was to negotiate features.\"}, {\"type\":\"paragraph\",\"text\":\"I have a suggestion. Let\u2019s write down on paper arguments for and against. You do that, we do that and then we do a meeting only on that so we can just have the arguments laid down beforehand and prepare a bit more.\"}, {\"type\":\"paragraph\",\"text\":\"We\u2019ll write down that situation where it is like zero confs or bust. We are like zero confs or bust, you are like zero conf all day everyday. I think that\u2019s the difference how we\u2019re approaching the protocol design here. Sounds good.\"}, {\"type\":\"paragraph\",\"text\":\"On [PR 906](https://github.com/lightning/bolts/pull/906) the feature bit one, we are going to do a release super soon once we know this is there because we broke stuff unfortunately, my fault.\"}, {\"type\":\"paragraph\",\"text\":\"Ok I can test it and review it when it is ready.\"}",
    "body": "\nName: Lightning specification call\n\nTopic: Agenda below\n\nLocation: Google Meet\n\nVideo: No video posted online\n\nAgenda: <https://github.com/lightning/bolts/issues/936>\n\nThe conversation has been anonymized by default to protect the identities of the participants. Those who have given permission for their comments to be attributed are attributed. If you were a participant and would like your comments to be attributed please get in touch.\n\n# BOLT 7 onion message support\n\n<https://github.com/lightning/bolts/pull/759>\n\nSo PR 759 is built on PR 765 because we used the route blinding to decrypt where the end is going to go. After feedback from Matt I think we have a pretty good, close to final on onion message support. The original onion message was basically exactly the same as we do for HTLCs. The only difference is that it could be variable size. You unwrap the onion, figure where it is going next and send it onwards. The endpoint would have some extra fields to contain the data. That\u2019s still the case but now it is always a blinded onion. When you unwrap it you get this second layer of encryption and then you decrypt that. The reason for that is that we were using that for onion replies. I send you an onion message and I include this route blinding path that you can drop into the onion to get the reply back to me. But that made it asymmetric and you could tell the difference between someone sending you the onion message and sending the onion reply. We went \u201cNo that\u2019s it. It is always blinded even when that is gratuitous.\u201d There is no particular reason to blind a message if you know exactly where it is going. But it does make them uniform. Basically route blinding is now compulsory in an onion message. But it is pretty straightforward. It is exactly the same onion format we use in HTLCs, you pull it apart. I have test vectors, Thomas H of ACINQ has been working his way through them. He found some bugs in my test vectors that basically work but I\u2019ve had some cut and paste errors that I have to get back to. He has got interoperability between c-lightning and eclair on a slightly previous revision of onion messages. We tweaked the spec in a couple of small ways for the final version. The message number is now 513, it was previously in the gossip range and everyone objected to that, it was obviously not a gossip message. Now it is 513 which is undefined range. You can ignore it because it is odd. There were a couple of fields that were unified when t-bast did the route blinding stuff that will be the same as the ones we want to use in route blinded HTLCs. There were some minor field renumberings that don\u2019t affect anyone except c-lightning, c-lightning now has to do both. I\u2019ve implemented that and I think we are very close to finalizing on the two implementations there. I\u2019m hoping that will happen this week. I would really like Matt to get back and reproduce that so we\u2019ve got a three way compatibility test for at least that part. That is all looking really good. Hopefully that won\u2019t change again. Obviously that leads us into offers which is the next bikeshedding thing on top of onion messages. I am hoping once we\u2019ve formal interoperability of the slightly tweaked spec we can have our two implementation bake off test and all the test vectors complete. Definitely by next meeting we should have both implementations 100 percent I hope.\n\nI am pretty sure we will have by the next meeting complete interoperability between eclair and c-lightning. If people have time to review the PRs and find things that look odd. Maybe on the route blinding one, by specifying the route blinding for payments, it was mostly useful for onion messages as well. Right now there is the real spec part that updates the BOLT and only adds the things that are necessary to the onion message and the low level utilities for route blinding. I also have a separate [document](https://github.com/lightning/bolts/pull/765) that is a proposal format with more details and documents and more brainstorming kind of things around payments. I am not sure that should be merged initially so let me know if there are parts to remove in the first version that we will add when we actually use route blinding for payments. That may make sense.\n\nc-lightning has support in experimental mode for an earlier version of the route blinding for payments too. It is pretty trivial. It needs to be updated for the modern spec. It is really easy. The only thing that we do not support in onion messages is route blinding direction by short channel ID because I simply haven\u2019t implemented it yet, there is a FIXME. You can either specify the next hop by short channel ID or by full node ID. I do not yet support short channel ID but I will fix that before the next release. I originally ripped it out but t-bast put it back because it makes more sense for payments anyway. It is nicer, it is more compact, you use less space in the onion. For payments where the onion is a fixed size that is perhaps more critical.\n\nIt sounds like both route blinding and onion messages, we might have some level of interoperability between c-lightning and eclair by the next meeting?\n\nYeah we had it then we tweaked it. We both broke it in the same way.\n\nIt is Thanksgiving week here in the US so you\u2019re probably not going to get a lot of work out of the rest of us.\n\nOne more question about the onion messages. We\u2019ve had a discussion on Twitter and so on and I am still surprised that none of you seem to be very concerned about abuse of these onion messages. You can route them in 27 hops all across the network, it seems like we are stepping over that as easy as we did with the HTLCs and replicate the same problem in onion messages. I know they are lightweight etc but isn\u2019t there the endgame here that no one wants to forward onion messages and you can only connect directly. You have no privacy gain because of that. You might as well have not done onion messages.\n\nI am concerned as well.\n\nThere are a few things we can do with onion messages that we can\u2019t do necessarily with HTLCs. Maybe we can approximate the failure modes of HTLCs. One obvious thing that I think Rusty has mentioned before is the ability to tell a peer \u201cYou are sending me too many onion messages. Shut up or slow down.\u201d That peer doesn\u2019t just blindly drop onion messages based on a flow rate to that next peer who told them to slow down but actually can do it based on the previous hop. That peer who gets told \u201cSlow down\u201d, they can look at their inbound onion message flows and say \u201cThe source of all these onion messages is that peer. I am going to rate limit him and I am going to tell him to slow down.\u201d You can do a backwards flowing rate limiting or flow control there. A little bit naive flow control but does let you rate limit someone and then tell them to do it based on source. If you are rate limiting based on source and it flows backwards\u2026\n\nThe trick is you do it without state. What happens if you are being flooded then next time you go into the thing that you have to rate limit, you tell the source to rate limit it. You are going to hit the path that is flooding you most. If someone is flooding down one path that will get it. If someone floods the entire network, sure.\n\nThe answer to flooding the whole network is you stop accepting onion messages for forwarding except from someone you have a channel with. Now you can\u2019t necessarily flood everything.\n\nWould that really address things though? It seems like rate limiting is a requirement and the existence of that destroys quality of service. You don\u2019t really have any guarantees. It is even more unreliable as a messaging thing. Maybe that is ok for certain things.\n\nYes, the internet works by doing retransmissions.\n\nThe Tor network.\n\nTor has centralized rate limiting. We can do that too but then we\u2019re biting off a pretty big challenge there.\n\nTor does not have centralized rate limiting.\n\nWhat do you mean? The directory authorities.\n\nTor has centralized selection of pseudo honest nodes but anyone can connect and start flooding the Tor network. They don\u2019t have centralized rate limiting.\n\n<https://blog.torproject.org/research-problem-adaptive-throttling-tor-clients-entry-guards/>\n\nIt is closed membership in a sense.\n\nNot on the client side though.\n\nSure. All I\u2019m getting at is that it seems like we are trying to replicate the Tor network, or a subset, it just seems that\u2019s a lot to bite off basically. Maybe we\u2019ll get there when we get there. We\u2019d just end up with VPNs over Lightning. That sounds cool, I thought that was cool a few years ago, I did talks and stuff but now I\u2019m more wary of it.\n\nThe point is that yes you have to rate limit, if someone tries to spam you with 100MB a second of onion messages you will rate limit them and tell them to shut up. But if you could flow that flow control back to the source then you\u2019re not as strictly impacting the quality of service for others. You can actually push the flow control back through honest nodes to the border where you have some node\u2026\n\nThere is no sybil resistance here because the attacker could just create another ID. If we are not rate limiting people who don\u2019t have a channel, creating new node IDs and just sending anonymous messages is really easy. That goes back to accepting onion messages from people who have channels. Another thing that I wanted to mention is we need to think about what is the degraded. In most cases that we want to use onion messages for the degradation of service when you just drop the onion messages would just mean that you may be losing privacy by having to connect directly, one hop through your ISP instead of a longer route, but that is probably acceptable in most cases right?\n\nThe streaming movies thing is kind of interesting. It depends how our rate limiting is. If our rate limiting is relatively aggressive\u2026. You basically want one message back and forth generally, You are very low actual requirements. Your rate limiting can be fairly aggressive. It will be interesting to see if we see massive amounts of abuse. We\u2019ve seen some HTLC abuse.\n\nIt seems like botnets are going to love this thing.\n\nBotnets can use HTLCs though, they can use failed HTLCs for confs and we haven\u2019t seen that yet.\n\nBotnets do use Tor, they use all kinds of other stuff.\n\nI understand that. It just seems like to me we are just adopting this other network type due to necessity. I am just afraid what happens in future.\n\nIf you require a channel no botnet is going to use this because no botnet is going to open a channel at each endpoint of the botnet.\n\nI like your monetization strategy, that\u2019s awesome.\n\nI\u2019m just caught on the arbitrary data thing. The implications of that, whether it is things that we like or we don\u2019t like, what people can use it for in the future, the tension that can draw. I understand it is super useful for other stuff but I\u2019m just worried about the tail end of it. Maybe it is not going to happen.\n\nI think we\u2019ve built that already unfortunately. HTLCs built that already.\n\nOnion messages are no more or less s\\*\\*\\*\\*y. The only difference with an onion message assuming proper rate limiting like we described is you have to pay maybe a 100 msat fee or 1 sat fee. That is the only difference. And you get much smarter rate limiting for onion messages because you can push the rate limiting back towards the sender.\n\nI\u2019m not very optimistic, I guess we\u2019ll see where it goes. I guess people will handle it when we get Wireguard over Lightning. That sounds cool.\n\nI do anticipate at some point that we will see people paying for HORNET. There are definitely going to be LSPs, people who run Lightning nodes and are quite happy to sell you bandwidth. I expect that this rate limiting will become too aggressive for that kind of usage. It will be interesting to see where people set the rate limits.\n\nHave people implemented the rate limiting today or just hypothesizing how it could be done in the future?\n\nNo we are handwaving, I haven\u2019t rate limited. There is a FIXME in the code, you should rate limit here.\n\nI assume before shipping people will have naive rate limiting. The previous discussion of being able to tell the peer to shut up and slow down is something that would need to be spec\u2019ed in the future.\n\nPayment flow control and data flow control, I don\u2019t know. It seems like a lot but that\u2019s just me maybe.\n\nAt least data flow control is easy.\n\nBut it is something else entirely.\n\nWho do you rate limit if you get your limit on two paths? You send to both, you go \u201cI\u2019m rate limiting you by the way.\u201d When it goes in the outgoing you\u2019d go \u201cThat\u2019s rate limited. I am going to push back and say by the way you\u2019re rate limited.\u201d And that flows back indefinitely. In effect yes you\u2019d end up degrading the entire network down to your rate limit but that\u2019s a feature if you are flooding the entire network.\u201d The question of can I jam an uninvolved party at very small cost, you can jam in the sense that you can send them lots of traffic and they can start rate limiting traffic. That\u2019s way, way better than them jamming your HTLCs where they jam your ability to make payments. This is the OP_RETURN argument. It is far worse for them to spam you with HTLCs so you provide them with this low overhead method of sending stuff so they don\u2019t do the worst thing.\n\nI guess we\u2019ll see how it develops.\n\nI don\u2019t think we\u2019re making any progress here so we should move on.\n\n# Add payment metadata to payment request\n\n<https://github.com/lightning/bolts/pull/912>\n\nPR 912, the current state, it looks like there are a few updates. Christian posted an update 42 minutes ago, Christian is doing the normal thing of contributing to the spec on meeting day, thanks Christian.\n\nIt is just a minor formatting\u2026\n\nThere is some formatting discussions on the thing, I think I had a similar formatting discussion comment. It looks like there is one implementation from the eclair folks, t-bast had something.\n\nLND also has send and receive in a PR.\n\nIt looks like it is just pending resolution of some spec update comments that can happen on GitHub and then cross implementation tests. Are there any comments that need higher bandwidth discussion that should come up now? Or can we resolve everything on GitHub?\n\nIt is interesting that LDK is doing this already, just with the payment secret but there is an immediate use for this, that is quite nice.\n\nYeah it turns out on the LDK end we don\u2019t need a whole lot of data so we are just going to do this today with the payment secret. We don\u2019t need more data.\n\nIf you want to do just in time insertion of invoices and just replicate the invoice as if you already had it in the database then inside that payment metadata you need to put all the fields that were used to create the invoice, the invoice you didn\u2019t store, so you can recreate it when the payment actually comes in. How is this going to work out? Is every implementation going to\u2026\n\nOn the LDK end we are not talking about doing that. LDK splits the responsibilities there. We handle authenticating the payment which is the standard payment secret concept and then we let the user deal with storing actual concrete metadata. Description and all that kind of stuff. We anticipate with our change that users will still actually store data about the payment in their own local database but that is outside of the scope of LDK. LDK will generate payment secrets such that we can authenticate the payment by amount and authenticate it with the sender. We don\u2019t actually do anything else, that is not our job.\n\nIf you want to take that one step further and you also don\u2019t want to have this user database, that is possible as well with this. Everything in the metadata, you can just insert it on the fly. It is very stateless, it is also very cheap. You can generate as many invoices as you want. If they don\u2019t pay they don\u2019t take up any space. There is no expiration. Will something be standardized or will a loose standard emerge on how to do this? Maybe if we copy over\u2026\n\nSomething, something bLIP or SPARK, whatever people want to call it.\n\nI think it depends on what the emergent use cases will be. Maybe it is going to take an initial iteration but it is non-binding which is cool.\n\nMaybe in hindsight we should have made the payment secret of variable length. Now at least we are forcing to be some kind of random number so maybe it is safer.\n\nIt should be variable size. That is something I regret.\n\nWe did discuss it at some point but then we said it is too dangerous, people will use one byte and then it is not secret anymore, something like that.\n\n# Advertize compression algorithms in init\n\n<https://github.com/lightning/bolts/pull/825>\n\nt-bast and I were communicated a little bit about doing some cross implementation tests. I have a testnet node with this up, I think t-bast has too but I was too lazy to setup my testnet to support Tor. It does need a rebase and it looks like Vincenzo has some comments on GitHub which should be resolved on GitHub. Is there anything that needs high bandwidth discussion and should be discussed here? Ok, follow up on GitHub, we will introduce some cross implementation tests on that soon as well.\n\n# Dynamic DNS support in gossip messages\n\n<https://github.com/lightning/bolts/pull/911>\n\n<https://github.com/lightning/bolts/pull/917>\n\nNext we\u2019ve got these two PRs for gossip addresses, DNS hostname and to tell your peer what IPs you have when you connect. Are there implementations of this? Or is it still just theoretical?\n\nThe IP one, there is a c-lightning and eclair implementation but last I tested I don\u2019t remember, I think I sent some comments to m-schmoock because there were issues that I found in the c-lightning implementation. I don\u2019t know if that has been fixed since then.\n\nIt is still a pull request, we haven\u2019t merged it yet. Unfortunately Michael is not on the call. It is still a work in progress as I understand it but the spec seems pretty straightforward.\n\nSounds like c-lightning and ACINQ are working on cross implementation testing and nothing worth discussing here.\n\n# BOLT 2 and BOLT 9: introduce feature bit to gate new channel_type feature\n\n<https://github.com/lightning/bolts/pull/906>\n\nWe shipped something that messed up, PR 906 basically, this is the feature bit one. I think we all interpret the presence of the feature bit and sending the value slightly differently. In a way that works sometimes and doesn\u2019t work other times. I am getting some reports, I think y\u2019all always require the channel type to set if the feature bits are there right? You respond with one even if we didn\u2019t send one? I just want to make sure that is the fix.\n\nWe always spawn with one because it is an odd TLV even if you didn\u2019t set the bit or didn\u2019t send anything, we are going to respond with something.\n\nBut what are you going to respond with if I didn\u2019t send anything?\n\nWhat we are going to use, what will automatically picked up by the normal feature bit negotiation.\n\nI see. You are sending the implicit one even if I didn\u2019t send one?\n\nYeah exactly.\n\nI think we don\u2019t like that because we didn\u2019t choose anything and we exit out there.\n\nWe figured it is just making it explicit something that was implicit. The other side can just ignore so I thought it was a win. It was less code because we just send it all the time.\n\nIf you didn\u2019t advertise this feature bit you should be ignoring.\n\nc-lightning does that as well too right? Ok we can fix that.\n\nThere is also a comment on the PR 906. Right now you don\u2019t ignore obviously if you receive a channel type even though the feature bit is not set, the feature bit doesn\u2019t exist yet because the PR is not merged. The PR currently says that you should ignore the channel type if the feature bit was not set. I commented and t-bast seems to agree that you should continue to optionally interpret the TLV whether the feature bit is set or not. In part because nodes do this today.\n\nDon\u2019t feature bits gate inclusion of a TLV? If you are setting the TLV and I have the feature bit I wouldn\u2019t read it right?\n\nYou can read it if you want. It is there. It is used today, that is what the spec says today. I know LDK does that, I don\u2019t know what other people do. We send the TLV and we interpret the TLV whether there is a feature bit or not.\n\nInteresting. We\u2019ll parse it but we\u2019ll ignore it. That seems like a different requirement. We\u2019ll only look at it if the feature bit is set.\n\nIf you want to not send a channel type in response then that would be fine too. My proposed change here is we\u2019ll send it, we\u2019ll parse it if we receive it, we don\u2019t care about the feature bit. And we\u2019ll also eventually now set the feature bit. But if you want to ignore the field because we didn\u2019t set the feature bit, you are talking to a current version of LDK, not a future version, then that\u2019s fine as long as you don\u2019t respond with a channel type in the accept channel message. We\u2019ll just say \u201cClearly they didn\u2019t understand it and that\u2019s fine\u201d.\n\nI\u2019ll need to go back and read the original PR.\n\nI see what you are saying. But if it is present in both messages and we only send it if it was present\u2026\n\nThe problem is what you are suggesting is a change from the current spec. The current spec says you should just send it and if you receive it you should parse it. If you understand it and you parse it you should respond with something in the accept channel message.\n\nCurrently it is gated on both sides.\n\nIt is making it slightly tighter yeah.\n\nIf we had done it the right way, if we\u2019d put a feature bit in the first place then it is pretty easy. Set the feature bit and send it. If you don\u2019t set the feature bit don\u2019t send it. And then it is very easy. But we didn\u2019t do that. Now it is kind of implied, if you sent it that means you wanted me to use it. If we both send it then we\u2019re using it. If we didn\u2019t both send it then we\u2019re not using it at all.\n\nI think it is compatible with the behavior in that if I\u2019m sending the bit I\u2019m going to send it. I can remove that to make that looser but I think it is compatible with our behavior of we only send it if we send a bit.\n\nThe proposed change makes existing implementations do something that they must not do.\n\nThey won\u2019t set the bit but they will send it.\n\nThey won\u2019t set the bit and they will send it. The proposed change makes that something you are not supposed to do.\n\nI can fix that super easily. I think I found the source of that other bug. I think there is another one with eclair but I\u2019ll message you about that t-bast. Then we can hopefully do the part release.\n\nI need to reread the full text but my intuition is that it would still be the case whether the feature bit is set or not, if one node sends the TLV and the other node sends back the TLV in the accept channel then you\u2019re using the TLV whether the feature bit is set or not. If a node wants to gate responding with the TLV on the feature bit they can do that, that\u2019s totally fine. But if both TLVs are there you are using them whether the feature bit is set or not.\n\nI see what you are saying. We arrived at that conclusion to set the bit differently but you\u2019re right. If both people set the type we\u2019re using it.\n\nI just wanted to make sure, that would be the current behavior.\n\nAfter this gets merged and everyone has updated then everyone will set the feature and everyone will send the thing. It is a future point if you didn\u2019t set the feature you wouldn\u2019t send the thing.\n\nI think that\u2019s the other error that we are seeing here. Interoperability testing will figure it out.\n\n# Simple turbo channels enablement\n\n<https://github.com/lightning/bolts/pull/910>\n\nTurbo channels, PR 910, are there implementations of this? We\u2019re working on it, we\u2019re getting there.\n\nI think Eugene has one now that he has tested. I think there are just questions on chantype stuff. We are talking about zero conf.\n\nMy only concern was there is no chantype for zero conf explicitly. I left a comment.\n\nZero conf isn\u2019t a different channel construction, it is not really something you have to remember. Originally channel types were stuff you had to remember. \u201cThis is a static remote key\u201d or stuff that was obviously persisting across the channel. There is one thing however you have to remember. If this is a private channel and you don\u2019t want them to route by the short channel ID\u2026 Let me pull up the PR, I should mention turbo in the title then I could find more easily. I think the last commit may have added this, there is a pile of 8 fixes. Now there is a channel type but that channel type means don\u2019t you dare route by short channel ID. That\u2019s cool and the reason that is cool is because when we have channel type upgrade, which is another PR, you can take the existing private channel and then go \u201cFrom now on no longer route via short channel ID. We are going to use the alias thing now.\u201d For a normal channel you can route by both. I can give you an alias and you can use either. But obviously for an unannounced channel in the ideal world you would never route by short channel ID to avoid probing. You can\u2019t do that today because it breaks back compatibility. You don\u2019t know when the other side is ready. They have got to be handing out aliases in their invoices and stuff like that. By adding a short channel ID just for the private case that gives you that feature that you want.\n\nI saw the recent change. I was mostly referring to if I start a channel flow and I have the feature bit and they have the feature bit, they want zero conf. When the acceptor sends accept channel it is kind of like \u201cI hope you open a zero conf channel to me. I hope you send `funding_locked`.\u201d In the spec currently if a `funding_created` is sent back then the initiator agrees to open a zero conf channel, a promise almost. The current wording is very open ended I think.\n\nWe should make it clear that if you offer this ability and you are funding the channel then you should do zero conf. You\u2019ve got nothing to lose, I trust myself so I will zero conf for you. Whether you accept it or not is obviously beyond my control. You might decide to delay for some confs. But the opener should always send, I\u2019ll check the wording. The idea is to prefer this model of opening in future. If you advertise this you will aggressively send `funding_locked` before it is really locked. I will check the wording to make sure that is explicit enough.\n\nHis point is he preferred to be more explicit. Y\u2019all are saying they don\u2019t have to send it. We\u2019d like to make that explicit.\n\nThere are two things here. One is do I trust you? There is a whole trust question. Am I prepared to let you open a zero conf channel and route stuff and accept payments and everything else? I am not quite clear how you would do that, that decision may come later.\n\nThat decision is entirely out of band basically. It almost doesn\u2019t need to be in the protocol because do I trust you is a question that is going to be decided entirely out of band via some mechanism of either talking to someone if it is a regular node or some LSP, whatever that system is. It being in the protocol doesn\u2019t seem to add very much because they already know who they are talking to, they already have some special protocol.\n\nYou\u2019ll start bouncing HTLCs off.\n\nDoes that mean you can\u2019t signal it within the protocol? Otherwise every party opening a channel with me if I have the feature bit set is somehow assuming that I may send it. Versus if I am opening a channel outbound and I don\u2019t set the bit they know we are not doing zero conf. To me it is about the explicit versus implicit type of thing. Do we implicitly know because I don\u2019t know who Matt actually is in real life that we are not doing zero conf? Or can I set in my message \u201cHey we are doing a zero conf\u201d.\n\nIt seems like you are trying to interpret the bit in a way that the bit doesn\u2019t mean. The bit does not mean zero conf. That\u2019s not what the bit means.\n\nI think the difference is that y\u2019all are interpreting it as behavior while we\u2019re thinking of it as a channel type. If we can add logic to validate that channel type and let users explicitly open that channel type. Y\u2019all are saying \u201cI have the bit set. I might send it, I might not\u201d.\n\nI think the UX will be other way round. Matt opens a channel with me and then he pings me and goes \u201cYou don\u2019t trust my node yet, I can\u2019t route through you\u201d and I go \u201cCool, I am going to flip that on\u201d. There is no way to change the channel type after we\u2019ve negotiated it. It depends how your controls are going to work. If beforehand you are going to have a vetted list of nodes that you trust then when we\u2019re talking obviously in the protocol I could say \u201cBy the way I am perfectly happy to open this zero conf with you\u201d. When you open a channel with me I go \u201cYeah I trust you\u201d and you know. But I don\u2019t know how that would extend to the case where after you\u2019ve opened the channel with me I decide that I trust you and I\u2019m going to do the thing.\n\nWe\u2019re talking about two different feature bits here. Y\u2019all have the option SID but we\u2019re thinking of another funding level bit basically.\n\nYes. You are proposing adding another feature bit.\n\nI was talking about a channel type.\n\nWhich is a bit in this case with the way that it is set up.\n\nIt would technically be the same.\n\nWas your suggestion that if `funding_created` is sent back in response to `min_depth=0` that the initiator promises to open a zero conf?\n\nYou shouldn\u2019t be promising to open a zero conf in the spec.\n\nIf you set `min_depth` as zero then you\u2019re saying you\u2019re good. At the moment the opener says \u201cI want to open this channel\u201d and the acceptor says \u201cHere\u2019s my min depth\u201d and usually that is 3 or whatever. If I trust you I would set that to zero and it says that in the spec. Set that to zero implying that I\u2019m ready to go whenever, as fast as the message can get through I will trust your channel. We do have a flag explicitly in the protocol, a way of saying \u201cI trust you\u201d. On the other side we are saying you should always open zero conf. If you are the one doing the opening you should `funding_locked` aggressively immediately because you are signaling that you are all good. It is the receiver side, the acceptor side, in that case we do have a method of you saying \u201cYes I want this to be a zero conf channel\u201d. Now we could also put it in a channel type somewhere but what I am saying is I think in a lot of use cases it is going to posthoc. After you\u2019ve opened the channel you will suddenly decide that you want it to be zero conf. There\u2019s no really good way of doing that. The way to do that is you actually send the `funding_locked` early. You might have set `min_depth` as 3 but that is a hint.\n\nTwo things, we have something in mind basically where we\u2019ll know ahead of time, not the after the fact thing. It seems like the flow is different, you are thinking about it differently. Right now the acceptor sends `min_depth` meaning the initiator can\u2019t say \u201cLet\u2019s open a zero conf\u201d. The acceptor says \u201cI\u2019m going to make it zero conf\u201d. I think that is the control flow we want to flip basically. To allow the initiator to say \u201cI\u2019m going with zero conf\u201d which also lets the acceptor assert that this is going to be zero conf and they\u2019ve opted into it as well.\n\nIn the future the sender will always open zero conf, always. Every channel will be zero conf, everyone will be zero conf. There is no non zero conf anymore. \u201cHere\u2019s the feature, I support zero conf\u201d.\n\nMoving to full RBF in v24, full RBF and zero conf everywhere don\u2019t really go together super great.\n\nFor channel v2 stuff?\n\nBitcoin Core is planning to ship in v24 full RBF, so every transaction is RBFable. Rusty\u2019s point is that the initiator knows that they are not going to RBF and that\u2019s totally on the initiator\u2019s side. The receiver is the one who has to decide do I trust you to not RBF or do I set it at some `min_conf`.\n\nIt just feels like the control flow should be flipped. Let\u2019s say I\u2019m opening a zero conf with Rusty and he doesn\u2019t like me. I send `open` with chantype zero conf or the bit, whatever else, and he sends me the `reject` and now we know. There is no ambiguity of \u201cI opened it. I want a zero conf. Is he going to go first?\u201d I think we\u2019re trying to eliminate the ambiguity. The initiator says \u201cWe\u2019re doing it\u201d and then they deny immediately. Otherwise you are in some limbo. Are they going to send it or are they not? \u201cI guess they didn\u2019t send it, too bad\u201d. We think with the protocol we have in mind not having this explicit thing in there makes it hard to reason about what is going to happen. I feel like we have different use cases in mind. You are thinking \u201cAfter the fact we decide to make it zero conf\u201d while we\u2019re thinking \u201cWe are setup to do a zero conf channel\u201d.\n\nYou are not going to accept zero conf from anyone.\n\nYes, which is why you\u2019ll send the `reject` message.\n\nThe point is no one is going to say \u201cI accept this from everyone\u201d and so there is always going to be some out of band negotiation.\n\nYou are assuming a lot about how that negotiation will take place. Rusty is assuming that the negotiation will take place after we already opened the channel\u2026\n\nNo I wanted to allow that.\n\nI am just assuming there will be a negotiation. There doesn\u2019t need to be anything in the protocol at that point. There is implicitly.\n\nIf people are doing it like that today, we are trying to add something in the protocol.\n\nYou can\u2019t get away from that. You can add as much as you want to the protocol, there will still be some kind of out of band negotiation to say \u201cHey can you mark my node as trusted so I can open a zero conf channel with you\u201d. At that point I don\u2019t need it in the protocol.\n\nSure, but right now what doesn\u2019t exist direct feedback or explicit acknowledgement of that relationship within the protocol.\n\nThere is, if they reply with `min_depth=0` that means they have accepted that they are ready to go with a zero conf channel. But it is not in the channel type.\n\nIt is basically a delayed three way handshake. I send it, you send something\u2026 versus me just sending it.\n\nNo you send that at the same time you send the channel type, it is literally in the same package I think.\n\nBut the responder sends `min_depth`.\n\nThey would also send the channel type.\n\nThe difference is me the initiator, I can\u2019t initiate a zero conf and then have you accept or deny it. You denying it is basically you sending the error message or the warning.\n\nBut it is the same message flow.\n\nIt is not the same message flow.\n\nThe difference is that instead of the acceptor failing it you would then fail it. The opener would then reject and go \u201cNo you didn\u2019t put a zero min_depth so I\u2019m not going to open this with you\u201d. Is there a case where you would want to not fallback to a non-zero?\n\nYes. We have a specific use case. If it is not zero conf we\u2019re not doing it because we wanted zero conf as the initiator.\n\nBut you don\u2019t need a feature bit for that either. What you are saying is you want a feature bit so that instead of an `accept_channel` message the receiver immediately sends an error message. You don\u2019t necessarily need to do that immediately, they can send that `accept_channel` and then the initiator can send back an error instead of moving forward.\n\nYou want them to send an accept and an error?\n\nNo, not the receiver. The receiver sends the accept and the initiator says \u201cWhoa, that funding_locked is not zero, I don\u2019t want to do this\u201d, sends an error, closes the channel and moves on. You don\u2019t need a new feature bit to do that. You can accomplish that by just sending an error message.\n\nIt is a different way of doing it. Philosophically maybe I\u2019m the odd one, I like things to be explicit on the protocol level.\n\nThe only thing I dislike about the channel type is that the channel type is persistent across the channel. In the long term it doesn\u2019t matter whether it was zero conf. It is a weird thing to put in the channel type. Using the message depth to indicate whether you are accepting zero conf or not\u2026\n\nYou could delete the bit, you could keep it in memory, I don\u2019t know.\n\nWhat do you think about the fact also that even if I tell you it is zero I can switch all my `funding_locked` and make it non-zero afterwards. You\u2019re not going to close that channel on me because we just went through the trouble of opening it.\n\nYou can always accept the open and then refuse to route or accept any HTLCs too.\n\nI feel like you can do a bunch of things. We are just trying to make things explicit for the computers and they know what we\u2019re doing. We have to handle all the extraneous cases where you do some random thing because you are buggy still. We are literally talking about a bit. You already store the bit.\n\nIt has to be another one because I stole this feature bit to mean something else. I stole the feature bit to mean don\u2019t route into the channel type already.\n\nThere are two different things. We are just talking about making the negotiation explicit basically. We can write down this flow as well to make it more clear.\n\nWe are all on the same page, I just don\u2019t buy that that is more explicit. I totally understand what you are saying. I don\u2019t buy that that is materially more explicit. Users don\u2019t see \u201cChannel closed with reason channel failed to open because you didn\u2019t accept zero conf\u201d. At the end of the day the user experience is still you see the same error message and the same failure reason.\n\nYou are assuming a lot about how negotiation will work in general, how out of bounds stuff will work in general.\n\nThe spec explicitly says if you trust them you should set the depth to zero. If they don\u2019t do that you go \u201cYou don\u2019t trust me so I\u2019m going to close the channel. I\u2019m not going to continue opening.\u201d We already have a flag, it is just that it is not in the channel type. If you put it in the channel type the failure is faster.\n\nIt fails faster by one packet.\n\nYes. That\u2019s lovely. Why do we have TCP Fast Open? It is one more round trip.\n\nOn the downside this would be worse for us because we will open everything zero conf and we want to fallback. We will have to reopen, \u201cThat\u2019s right, you didn\u2019t accept the zero conf channel type.\u201d Every time we would have to try again with the non-zero conf variant of the channel type. It is a lot more work for everyone else.\n\nYou seem to be living in a universe where everything is zero conf everywhere. We\u2019re like \u201cIt is going to be zero conf if both sides cross the t or sign here basically\u201d. I think we are looking at it differently in that regard as well.\n\nWe will be offering zero conf to everyone.\n\nAnd we wouldn\u2019t. We\u2019d only do it under very specific situations.\n\nWhy?\n\nOr one side setting it explicitly.\n\nThe receiver can always immediately send a `funding_locked`. Now you\u2019re sitting on your `funding_locked` for no reason.\n\nWe wouldn\u2019t do anything because we didn\u2019t set the bit. This is just constraining the paths of the software and what we expect. It seems like people at least acknowledge that there\u2019s a condition where maybe you want the initiator to be able to specify this upfront. And it fails faster. At least we have those two acknowledgements. We won\u2019t be setting zero conf for everything once this is in as well too.\n\nWe will. So we definitely do not want your dance where you have to reconnect and offer a different channel type. That is why. It is a lot more logic for us to change this.\n\nIt is still implementation phase.\n\nMore code in exchange for half a RTT, faster failure does not seem like it is\u2026\n\nYou\u2019re trivializing the implicit versus explicit thing. More code is super relative.\n\nIt is still explicit. There is still an error message, it is still incredibly explicit. If you interpret the bytes on the wire in the way described in the spec it is equally explicit in both cases.\n\nComment: Making the \u201cwe always open zero conf\u201d much harder in exchange for a tiny speed improvement for those that don\u2019t should make the `channel_type` undesirable. 1/2 RTT in exchange for 4 RTT for a reconnect.\n\nAre you really going to do everything zero conf after this?\n\nWhy not?\n\nYou can\u2019t really do that with 2 player channels. Anything that uses an interactive protocol, you start getting into trouble.\n\nThat is unspec-ed so far. We need to figure that out. Once the other party is putting funds in you cannot default to zero conf without a trust relationship. But in this case of simple open this is very simple. One side has nothing to lose by offering zero conf. In the case of simple open that is the funder.\n\nIf I said on Reddit every channel is now zero conf people will be like what?\n\nOn the initiator side I agree that the initiator has an incentive to always say zero conf. If he\u2019s the only one putting funds in the channel on the receiver side I agree that we would choose depending on other conditions. But on the initiator side I don\u2019t see why we would not do zero conf all the time.\n\nThe initiator might not just auto do zero conf because the market may price that default risk? If you have no marginal cost then you would but if there is a market premium for that service from an acceptor\u2026\n\nAgain that negotiation happens out of band. If you have an out of band price for accepting a zero conf then presumably that will be you have to set at least a `push_msat` of x in order for me to accept your zero conf. But if I just request a zero conf and set a `push_msat` below that you simply won\u2019t accept it and that\u2019s fine. You still do it at the protocol level because why not?\n\nI guess we just have different ways of looking at this risk, the feature itself and negotiation.\n\nWhat risk?\n\nI just want to make it explicit. I want to make sure that both sides are double opting in to this zero conf type thing. I send the feature bit, you decline. It is fast close. It does get in the way of this every zero conf thing. I don\u2019t know if that is a good idea. Maybe that is just simpler, to do zero conf all day, every day.\n\nWay simpler.\n\nEven from our perspective after implementing this code, is it just gating this new behavior?\n\nEven if we don\u2019t go there zero conf for everything having the ability to open a zero conf without having to first check with the node whether they would accept it is something that we need to have. If we end up aborting a fund channel because our counterparty did not accept the zero conf then we have to reconnect, that\u2019s way more code than the optimization we gain from closing half a roundtrip earlier.\n\nYeah we won\u2019t be doing that, that is dumb.\n\nWe won\u2019t be doing zero conf all day everyday.\n\nWhy would you possibly not offer this?\n\nBecause we want to make it explicit to the users.\n\nIn the current spec you can choose to not opt in.\n\nThe difference is y\u2019all won\u2019t be able to open it up and then find out after the fact if they accept it. From the receiver standpoint.\n\nYou do it by error, we do it by examining a field. It is the same thing.\n\nI want to be able to open up a channel without knowing if the relationship exists already. I find out once they get the open.\n\nWe want to try to open a zero conf channel. Our counterparty says \u201cNo go away\u201d. We have to reconnect, remember across these connections that they didn\u2019t accept it and retry without zero conf. That is way harder than just saying \u201cCan we try opening a zero conf?\u201d and the other side then says \u201cI don\u2019t want to\u201d and we are still good. We can\u2019t do better than falling back into a non-zero conf channel after trying a zero conf channel.\n\nIf we really wanted to do zero conf when they return with `min_depth` not equal zero we go \u201cNo sorry you are not zero conf enough for us. We only like zero conf things. We want people to trust us or whatever.\u201d We send an error at that point. I cannot imagine that it is priced except in a negative sense. c-lightning always offers zero conf and I can use it if I want and lnd doesn\u2019t.\n\nDo you all agree that the acceptor is the person taking on risk?\n\nYes.\n\nSo they decide.\n\nSo why not let them be explicit with that?\n\nWe are by setting `min_depth`.\n\nThey say \u201cHere\u2019s my min_depth, it is not zero\u201d. That is how they are telling you explicitly whether they are going to zero conf or not.\n\nY\u2019all are saying this lets me open up a channel and not know if they support it yet and they tell me later. Versus me just saying \u201cI want to open the channel\u201d and they say \u201cNo\u201d. That\u2019s the difference.\n\nRight because this is way simpler. You can offer it to everyone and they can accept or not on their own terms. You don\u2019t have to do this dance where you go \u201cI insist on a zero conf channel even though I don\u2019t care either way because it doesn\u2019t make a difference to me, I\u2019m opening it and I trust myself. I explicitly want to open a zero conf channel.\u201d They go \u201cNo I don\u2019t trust you\u201d. Then I go back and say \u201cNow let\u2019s open a normal channel\u201d. It is the dumbest protocol ever.\n\nDo we realize that this is the type of negotiation that we put into place with the explicit channel type? Remember we had a different type before. There was this double opt in thing. We said \u201cNo you\u2019ll just send the error and then try again\u201d. That\u2019s what this is. We\u2019ll have to do that anyway for any channel type because that\u2019s the way we decided to do negotiation.\n\nThey are different. The reason I think it makes sense for channel type to try some specific channel type, \u201cI want this anchor thing\u201d and you say \u201cNo\u201d. I\u2019m like \u201cOk maybe something else\u201d. But here the reason it is different is that I really think when you actually use it if a guy says \u201cNo to zero conf\u201d you still want to have a channel with them.\n\nBut we described a case where that\u2019s not the case. We only want zero conf.\n\nThen you send them an error going \u201cNo you didn\u2019t accept my zero conf\u201d.\n\nYou only want zero conf, it is for UX. Because otherwise the user opens it, they\u2019re waiting and maybe the wallet promised that they can send now but they can\u2019t because of this thing.\n\nI don\u2019t think the gain of gaining half a RTT is worth it in that case. You just reject and not complete the flow. They say `min_depth` is not zero.\n\nThe opener would close in that case instead of the acceptor closing.\n\nYeah that\u2019s the difference.\n\nThe opener would go \u201cNo you are not zero conf enough for me. I only want channels with people who trust me\u201d and they error out at that point. I am really looking forward to zero conf everywhere. If you trust my node then sure we\u2019ll do zero conf and if you don\u2019t that\u2019s fine we\u2019ll be normal. But you still get the other features that we want here.\n\nThe other thing, this negotiation isn\u2019t what we all signed up for. The whole try it, reject and then try again.\n\nNo remember the original proposal was mine, it didn\u2019t have that and everyone was like \u201cWe can do that if this ever occurs\u201d. I went \u201cOk let\u2019s make sure one of them never occurs\u201d.\n\nDo you remember the rationale? We were talking about how do you handle these weird feature bit combinations. I want anchors and something else that doesn\u2019t exist. How do we handle that? Just reject instead of both sides sending their overlap and then do it again.\n\nDo we want to try another PR? I think this gets back to the longstanding disagreement about what feature bits are for and required for.\n\nIt comes up a lot, we really view the way negotiations work differently. It seems like every time we are like \u201cLet\u2019s add a feature bit\u201d there\u2019s this massive campaign of \u201cNo feature bits are bad and we don\u2019t want to do them. It is going to make the code more complex.\u201d When I thought the whole point was to negotiate features.\n\nI have a suggestion. Let\u2019s write down on paper arguments for and against. You do that, we do that and then we do a meeting only on that so we can just have the arguments laid down beforehand and prepare a bit more.\n\nWe\u2019ll write down that situation where it is like zero confs or bust. We are like zero confs or bust, you are like zero conf all day everyday. I think that\u2019s the difference how we\u2019re approaching the protocol design here. Sounds good.\n\nOn [PR 906](https://github.com/lightning/bolts/pull/906) the feature bit one, we are going to do a release super soon once we know this is there because we broke stuff unfortunately, my fault.\n\nOk I can test it and review it when it is ready.\n\n\n",
    "body_type": "markdown",
    "created_at": "2021-11-22T00:00:00.000Z",
    "domain": "https://btctranscripts.com/",
    "url": "https://btctranscripts.com/lightning-specification/2021-11-22-specification-call",
    "categories": [
        "meetup"
    ],
    "tags": [
        "lightning"
    ],
    "indexed_at": "2024-03-21T16:33:36.662Z",
    "transcript_by": "Michael Folkson",
    "summary": "In an enlightening episode of the Lightning Specification Call, the discussion revolved around the significant updates and discussions surrounding BOLT 7 and its implications for enhancing the Lightning Network's messaging capabilities through onion message support. The conversation showcased the collaborative effort, with notable contributions from developers such as Matt Corallo and Thomas H of ACINQ, emphasizing the iterative process of protocol development. A pivotal shift towards mandatory route blinding for onion messages was discussed, aiming at privacy enhancement and uniformity across the network, despite its redundancy in scenarios where the message destination is already known. This evolution from the original design demonstrates a proactive response to community feedback and a commitment to interoperable standards.\n\nThe dialogue also highlighted the technical strides made towards achieving compatibility between different implementations, specifically c-lightning and eclair. Optimism was voiced regarding the resolution of outstanding issues, including test vectors and minor specification tweaks, underscoring the critical role of community feedback in refining aspects such as route blinding for payments. This iterative development process not only addresses technical challenges but also enhances the protocol's robustness, showcasing a unified effort to improve the Lightning Network.\n\nAddressing potential abuses of onion messages raised concerns about unrestricted routing and its implications for network security. Strategies like rate limiting and flow control mechanisms were debated, drawing parallels with existing networks like Tor to find a balance between preventing spam and maintaining service quality. These discussions reflect a nuanced understanding of the trade-offs involved in securing the network while ensuring its functionality.\n\nMoreover, the broader implications of onion messages for privacy and network operation were considered, acknowledging the feature's dual-use nature. The need for effective management strategies to mitigate potential misuse without compromising the network's core objectives was evident, underscoring the importance of ongoing dialogue and development efforts.\n\nFurther discussions in the podcast explored the introduction of payment metadata and dynamic DNS support within the Lightning Network, spearheaded by contributions from individuals like Christian Decker. These advancements aim at enhancing transaction processes and optimizing data transmission efficiency, reflecting the network's continuous pursuit of innovation. Debates on the necessity of feature bits for new channel_type features and the proposition of turbo channels underscored the nuances of feature negotiation and the quest for quicker channel establishment, highlighting the dynamic nature of the Lightning Network's development.\n\nA significant shift proposed towards utilizing aliases for routing, aimed at enhancing privacy and security, especially for unannounced channels, was discussed, alongside the growing preference for zero-confirmation channels to expedite transactions. The complexity of trust-based decisions and the call for more explicit guidelines within the protocol to formalize these arrangements were emphasized, pointing to the need for a balanced approach between efficiency, security, and trust.\n\nLastly, the podcast delved into the intricacies of implementing zero-confirmation transactions, examining the negotiation processes and their impact on user experience and system efficiency. The debate over making negotiations more explicit versus the practical benefits for end-users, and the tension between minimizing latency and the additional coding burden, highlighted fundamental disagreements on the risk and trust dynamics associated with zero-confirmation transactions. \n\nOverall, the discussions encapsulated in the podcast illuminate the ongoing efforts to refine and enhance the Lightning Network, balancing innovation with the need to address emerging challenges. As the network continues to evolve, these conversations will undoubtedly shape its future direction, promising a more secure, efficient, and user-friendly platform for digital transactions."
}